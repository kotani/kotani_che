{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvmRMOKTTdeHzDvlNG1eNb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotani/kotani_che/blob/master/ECG_MFER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install japanize_matplotlib | tail -n 1\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR4fvTFGRCAJ",
        "outputId": "8530a740-8bb5-434c-8b83-5f652243e2ed"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->japanize_matplotlib) (1.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "wrFm39T289yU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nb-rSHk9Bp4",
        "outputId": "f6bdc848-7254-4de7-e110-2e5162ad54f3"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "qgpShA5p9Don"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.io import ImageReadMode\n",
        "from torchvision.io import read_image\n",
        "from PIL import Image, ImageOps"
      ],
      "metadata": {
        "id": "beFYuUn49IiD"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "fNfYb4mS9xgo"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd = pathlib.Path().resolve()\n",
        "data_path =  pwd/\"drive/MyDrive/ECG_MFER/rawcsvdata_brugada\"\n",
        "normal_path =  pwd/\"drive/MyDrive/ECG_MFER/rawcsvdata_normal\""
      ],
      "metadata": {
        "id": "LiU7Kkjc9Ovf"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sampling,0.002,sec,Resolution,1.25,uV\n",
        "#I,II,V1,V2,V3,V4,V5,V6\n",
        "\n",
        "brugada_V2 = []\n",
        "#　↑なのでまずV2のみ取り出そう\n",
        "for csv in data_path.glob(\"*.csv\"):\n",
        "  np_csv = np.loadtxt(csv,skiprows=2, delimiter =\",\",usecols = 3)\n",
        "  #plt.plot(np_csv)\n",
        "  brugada_V2.append(np_csv)\n",
        "  #plt.plot(np_csv)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "pZUCnkhU9TaM"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_brugada = pd.DataFrame(brugada_V2)"
      ],
      "metadata": {
        "id": "Sv9Xw3hb9ZpN"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_brugada[\"pheno\"] = 1"
      ],
      "metadata": {
        "id": "RwvuMnHg9bhX"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sampling,0.002,sec,Resolution,1.25,uV\n",
        "#I,II,V1,V2,V3,V4,V5,V6\n",
        "\n",
        "normal_V2 = []\n",
        "#　↑なのでまずV2のみ取り出そう\n",
        "for csv in normal_path.glob(\"*.csv\"):\n",
        "  np_csv = np.loadtxt(csv,skiprows=2, delimiter =\",\",usecols = 3)\n",
        "  #plt.plot(np_csv)\n",
        "  normal_V2.append(np_csv)\n",
        "  #plt.plot(normal_V2)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "o1prNzHvHSrv"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_normal = pd.DataFrame(normal_V2)\n",
        "df_normal[\"pheno\"] = 0"
      ],
      "metadata": {
        "id": "7ORxkiX_HbDp"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_brugada, df_normal])"
      ],
      "metadata": {
        "id": "i3e5zhYEHiAM"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "t20tzpPlHiv6"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot"
      ],
      "metadata": {
        "id": "Y56gaothJpB4"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(\"pheno\",axis = 1)\n",
        "y = df.loc[:,\"pheno\"]"
      ],
      "metadata": {
        "id": "yicKyNvgH4m1"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "xzsWxkpqH-fA"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset"
      ],
      "metadata": {
        "id": "Y2keRDRCICgy"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#標準化する\n",
        "#X_train_std = (X_train.values - np.mean(X_train.values)) / np.std(X_train.values)\n",
        "\n",
        "#X_train_std = torch.from_numpy(X_train_std).float()\n",
        "#y_train = torch.from_numpy(y_train.values)"
      ],
      "metadata": {
        "id": "GMYtmRsCII-i"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#標準化しない\n",
        "X_train_std = torch.from_numpy(X_train.values).float()\n",
        "y_train = torch.from_numpy(y_train.values)"
      ],
      "metadata": {
        "id": "1UcXyAmNTopF"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(X_train_std,y_train)"
      ],
      "metadata": {
        "id": "ufZVMFjHIYa7"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "iVrRViIKMcS9"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle =True)"
      ],
      "metadata": {
        "id": "TkinkCI9L6DF"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "    self.layer2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = nn.Sigmoid()(x)\n",
        "    x = self.layer2(x)\n",
        "    x = nn.Softmax(dim = 1)(x)\n",
        "    return x\n",
        "  \n",
        "input_size = X_train_std.shape[1]\n",
        "hidden_size = 16\n",
        "output_size =2\n",
        "model = Model(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "cWyUG8ULI0fY"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)"
      ],
      "metadata": {
        "id": "k0z1xxbfKqQX"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "loss_hist = [0] * num_epochs\n",
        "accuracy_hist = [0] * num_epochs\n",
        "for epoch in range(num_epochs):\n",
        "  for x_batch, y_batch in train_dl:\n",
        "    pred = model(x_batch)\n",
        "    print(pred)\n",
        "    loss = loss_fn(pred, y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    loss_hist[epoch] += loss.item() * y_batch.size(0)\n",
        "    is_correct = (torch.argmax(pred,dim = 1) == y_batch).float()\n",
        "    accuracy_hist[epoch] += is_correct.sum()\n",
        "  loss_hist[epoch] /= len(train_dl.dataset)\n",
        "  accuracy_hist[epoch] /= len(train_dl.dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "punqOZTXLmFg",
        "outputId": "811811b1-2fae-4d34-eb1b-09050a5b1a00"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "        [0.0556, 0.9444]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1641, 0.8359],\n",
            "        [0.2588, 0.7412]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3326, 0.6674],\n",
            "        [0.1532, 0.8468]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0704, 0.9296],\n",
            "        [0.0435, 0.9565]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2450, 0.7550],\n",
            "        [0.1372, 0.8628]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2433, 0.7567],\n",
            "        [0.1322, 0.8678]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0705, 0.9295],\n",
            "        [0.1930, 0.8070]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2083, 0.7917],\n",
            "        [0.1537, 0.8463]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3312, 0.6688],\n",
            "        [0.0395, 0.9605]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0230, 0.9770],\n",
            "        [0.2848, 0.7152]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0464, 0.9536]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3915, 0.6085],\n",
            "        [0.0390, 0.9610]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0378, 0.9622],\n",
            "        [0.0941, 0.9059]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0472, 0.9528],\n",
            "        [0.1852, 0.8148]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0553, 0.9447],\n",
            "        [0.1610, 0.8390]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3321, 0.6679],\n",
            "        [0.0673, 0.9327]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0959, 0.9041],\n",
            "        [0.0217, 0.9783]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1519, 0.8481],\n",
            "        [0.1628, 0.8372]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1414, 0.8586],\n",
            "        [0.4822, 0.5178]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0672, 0.9328],\n",
            "        [0.0699, 0.9301]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0510, 0.9490],\n",
            "        [0.2688, 0.7312]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2103, 0.7897],\n",
            "        [0.0871, 0.9129]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1424, 0.8576],\n",
            "        [0.1433, 0.8567]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0453, 0.9547],\n",
            "        [0.1944, 0.8056]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0541, 0.9459],\n",
            "        [0.1878, 0.8122]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0959, 0.9041],\n",
            "        [0.1428, 0.8572]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1292, 0.8708],\n",
            "        [0.1659, 0.8341]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2044, 0.7956],\n",
            "        [0.1532, 0.8468]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0510, 0.9490],\n",
            "        [0.0673, 0.9327]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0689, 0.9311],\n",
            "        [0.1623, 0.8377]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3108, 0.6892],\n",
            "        [0.2777, 0.7223]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1566, 0.8434],\n",
            "        [0.0583, 0.9417]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3079, 0.6921],\n",
            "        [0.1127, 0.8873]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0535, 0.9465],\n",
            "        [0.1020, 0.8980]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0892, 0.9108],\n",
            "        [0.1089, 0.8911]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1233, 0.8767],\n",
            "        [0.0443, 0.9557]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1458, 0.8542],\n",
            "        [0.2534, 0.7466]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1230, 0.8770],\n",
            "        [0.0685, 0.9315]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0526, 0.9474],\n",
            "        [0.0895, 0.9105]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1234, 0.8766],\n",
            "        [0.1859, 0.8141]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1449, 0.8551],\n",
            "        [0.1580, 0.8420]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2287, 0.7713],\n",
            "        [0.1327, 0.8673]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2121, 0.7879],\n",
            "        [0.0401, 0.9599]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1515, 0.8485],\n",
            "        [0.1426, 0.8574]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1024, 0.8976],\n",
            "        [0.3156, 0.6844]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0829, 0.9171],\n",
            "        [0.4378, 0.5622]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1306, 0.8694],\n",
            "        [0.0880, 0.9120]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2566, 0.7434],\n",
            "        [0.0830, 0.9170]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1196, 0.8804],\n",
            "        [0.0501, 0.9499]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1213, 0.8787],\n",
            "        [0.2960, 0.7040]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1299, 0.8701],\n",
            "        [0.2269, 0.7731]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1496, 0.8504],\n",
            "        [0.5492, 0.4508]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0210, 0.9790]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0200, 0.9800],\n",
            "        [0.1106, 0.8894]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2369, 0.7631],\n",
            "        [0.1819, 0.8181]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0831, 0.9169],\n",
            "        [0.3273, 0.6727]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0917, 0.9083],\n",
            "        [0.3843, 0.6157]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0675, 0.9325],\n",
            "        [0.1861, 0.8139]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2124, 0.7876],\n",
            "        [0.3837, 0.6163]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2618, 0.7382],\n",
            "        [0.0650, 0.9350]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0524, 0.9476],\n",
            "        [0.0519, 0.9481]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2222, 0.7778],\n",
            "        [0.2342, 0.7658]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0681, 0.9319],\n",
            "        [0.1499, 0.8501]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0436, 0.9564],\n",
            "        [0.1610, 0.8390]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0651, 0.9349],\n",
            "        [0.4445, 0.5555]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1664, 0.8336],\n",
            "        [0.0851, 0.9149]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0331, 0.9669],\n",
            "        [0.0410, 0.9590]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2543, 0.7457],\n",
            "        [0.1903, 0.8097]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1241, 0.8759],\n",
            "        [0.0907, 0.9093]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1416, 0.8584],\n",
            "        [0.1433, 0.8567]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0917, 0.9083],\n",
            "        [0.0581, 0.9419]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1375, 0.8625],\n",
            "        [0.0574, 0.9426]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2689, 0.7311],\n",
            "        [0.0439, 0.9561]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0658, 0.9342],\n",
            "        [0.1814, 0.8186]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1605, 0.8395],\n",
            "        [0.1350, 0.8650]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3109, 0.6891],\n",
            "        [0.0935, 0.9065]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2057, 0.7943],\n",
            "        [0.0497, 0.9503]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1248, 0.8752],\n",
            "        [0.0665, 0.9335]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1531, 0.8469],\n",
            "        [0.0360, 0.9640]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5665, 0.4335],\n",
            "        [0.2347, 0.7653]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1453, 0.8547],\n",
            "        [0.1284, 0.8716]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0886, 0.9114],\n",
            "        [0.3129, 0.6871]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1009, 0.8991],\n",
            "        [0.2081, 0.7919]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0679, 0.9321],\n",
            "        [0.1461, 0.8539]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0505, 0.9495],\n",
            "        [0.1370, 0.8630]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0786, 0.9214],\n",
            "        [0.4812, 0.5188]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1007, 0.8993],\n",
            "        [0.0443, 0.9557]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0822, 0.9178],\n",
            "        [0.0890, 0.9110]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4261, 0.5739],\n",
            "        [0.3224, 0.6776]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1027, 0.8973],\n",
            "        [0.1191, 0.8809]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0357, 0.9643],\n",
            "        [0.0488, 0.9512]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0209, 0.9791],\n",
            "        [0.1325, 0.8675]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1575, 0.8425],\n",
            "        [0.1907, 0.8093]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2329, 0.7671],\n",
            "        [0.0504, 0.9496]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1430, 0.8570]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1433, 0.8567],\n",
            "        [0.1387, 0.8613]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0209, 0.9791],\n",
            "        [0.0888, 0.9112]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1007, 0.8993],\n",
            "        [0.0845, 0.9155]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2385, 0.7615],\n",
            "        [0.0833, 0.9167]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1575, 0.8425],\n",
            "        [0.0679, 0.9321]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0504, 0.9496],\n",
            "        [0.1474, 0.8526]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0887, 0.9113],\n",
            "        [0.0486, 0.9514]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3938, 0.6062],\n",
            "        [0.0515, 0.9485]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2344, 0.7656],\n",
            "        [0.0400, 0.9600]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0497, 0.9503],\n",
            "        [0.3243, 0.6757]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2523, 0.7477],\n",
            "        [0.0902, 0.9098]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1593, 0.8407],\n",
            "        [0.4465, 0.5535]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1432, 0.8568],\n",
            "        [0.1863, 0.8137]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1761, 0.8239],\n",
            "        [0.4278, 0.5722]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2685, 0.7315],\n",
            "        [0.0561, 0.9439]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3853, 0.6147],\n",
            "        [0.2032, 0.7968]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0640, 0.9360],\n",
            "        [0.1897, 0.8103]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1584, 0.8416],\n",
            "        [0.0494, 0.9506]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0435, 0.9565],\n",
            "        [0.0348, 0.9652]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3094, 0.6906],\n",
            "        [0.0777, 0.9223]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0649, 0.9351],\n",
            "        [0.1200, 0.8800]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1358, 0.8642],\n",
            "        [0.0876, 0.9124]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1816, 0.8184],\n",
            "        [0.0632, 0.9368]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0641, 0.9359],\n",
            "        [0.2361, 0.7639]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0893, 0.9107],\n",
            "        [0.0314, 0.9686]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0476, 0.9524],\n",
            "        [0.1179, 0.8821]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1431, 0.8569],\n",
            "        [0.1470, 0.8530]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1373, 0.8627],\n",
            "        [0.0802, 0.9198]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5700, 0.4300],\n",
            "        [0.0189, 0.9811]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1683, 0.8317],\n",
            "        [0.1866, 0.8134]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2371, 0.7629],\n",
            "        [0.0353, 0.9647]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1114, 0.8886],\n",
            "        [0.1317, 0.8683]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2165, 0.7835],\n",
            "        [0.0688, 0.9312]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2110, 0.7890],\n",
            "        [0.0563, 0.9437]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3267, 0.6733],\n",
            "        [0.1054, 0.8946]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1002, 0.8998],\n",
            "        [0.2701, 0.7299]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2224, 0.7776],\n",
            "        [0.0417, 0.9583]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1247, 0.8753],\n",
            "        [0.3198, 0.6802]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0881, 0.9119],\n",
            "        [0.4948, 0.5052]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1344, 0.8656],\n",
            "        [0.1545, 0.8455]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0422, 0.9578],\n",
            "        [0.1297, 0.8703]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0657, 0.9343]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0797, 0.9203],\n",
            "        [0.0207, 0.9793]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2208, 0.7792],\n",
            "        [0.1600, 0.8400]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1753, 0.8247],\n",
            "        [0.1619, 0.8381]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2076, 0.7924],\n",
            "        [0.0850, 0.9150]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1041, 0.8959],\n",
            "        [0.2684, 0.7316]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3151, 0.6849],\n",
            "        [0.1172, 0.8828]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0416, 0.9584],\n",
            "        [0.1215, 0.8785]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0637, 0.9363],\n",
            "        [0.1836, 0.8164]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3856, 0.6144],\n",
            "        [0.1661, 0.8339]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0473, 0.9527],\n",
            "        [0.1315, 0.8685]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0777, 0.9223],\n",
            "        [0.4887, 0.5113]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1414, 0.8586],\n",
            "        [0.0307, 0.9693]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0478, 0.9522],\n",
            "        [0.0610, 0.9390]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0467, 0.9533],\n",
            "        [0.1094, 0.8906]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0176, 0.9824],\n",
            "        [0.0852, 0.9148]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0632, 0.9368],\n",
            "        [0.1329, 0.8671]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0625, 0.9375],\n",
            "        [0.1416, 0.8584]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1281, 0.8719],\n",
            "        [0.2101, 0.7899]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0390, 0.9610],\n",
            "        [0.4462, 0.5538]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2268, 0.7732],\n",
            "        [0.1305, 0.8695]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0369, 0.9631],\n",
            "        [0.0644, 0.9356]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1224, 0.8776],\n",
            "        [0.0952, 0.9048]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0948, 0.9052],\n",
            "        [0.1733, 0.8267]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1774, 0.8226],\n",
            "        [0.0836, 0.9164]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0455, 0.9545],\n",
            "        [0.1438, 0.8562]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2238, 0.7762],\n",
            "        [0.0318, 0.9682]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0410, 0.9590],\n",
            "        [0.0623, 0.9377]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5520, 0.4480],\n",
            "        [0.0808, 0.9192]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1502, 0.8498],\n",
            "        [0.2024, 0.7976]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0314, 0.9686],\n",
            "        [0.1325, 0.8675]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0515, 0.9485],\n",
            "        [0.2199, 0.7801]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2583, 0.7417],\n",
            "        [0.0596, 0.9404]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0807, 0.9193],\n",
            "        [0.3017, 0.6983]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2390, 0.7610],\n",
            "        [0.3861, 0.6139]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2307, 0.7693],\n",
            "        [0.0446, 0.9554]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1390, 0.8610],\n",
            "        [0.0830, 0.9170]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0522, 0.9478],\n",
            "        [0.3144, 0.6856]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1842, 0.8158],\n",
            "        [0.0773, 0.9227]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1386, 0.8614],\n",
            "        [0.1145, 0.8855]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1344, 0.8656],\n",
            "        [0.4172, 0.5828]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0476, 0.9524],\n",
            "        [0.0824, 0.9176]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3214, 0.6786]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0297, 0.9703],\n",
            "        [0.2337, 0.7663]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0594, 0.9406],\n",
            "        [0.0448, 0.9552]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2454, 0.7546],\n",
            "        [0.5697, 0.4303]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0336, 0.9664],\n",
            "        [0.1406, 0.8594]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0975, 0.9025],\n",
            "        [0.0662, 0.9338]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0627, 0.9373],\n",
            "        [0.1767, 0.8233]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3212, 0.6788],\n",
            "        [0.0793, 0.9207]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3320, 0.6680],\n",
            "        [0.1752, 0.8248]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0886, 0.9114],\n",
            "        [0.0561, 0.9439]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0202, 0.9798],\n",
            "        [0.4066, 0.5934]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1214, 0.8786],\n",
            "        [0.1935, 0.8065]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1455, 0.8545],\n",
            "        [0.1390, 0.8610]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0886, 0.9114],\n",
            "        [0.1391, 0.8609]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0826, 0.9174],\n",
            "        [0.3190, 0.6810]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2731, 0.7269],\n",
            "        [0.0887, 0.9113]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1061, 0.8939],\n",
            "        [0.4640, 0.5360]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4393, 0.5607],\n",
            "        [0.0339, 0.9661]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2108, 0.7892],\n",
            "        [0.0875, 0.9125]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2391, 0.7609],\n",
            "        [0.1459, 0.8541]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1316, 0.8684],\n",
            "        [0.0503, 0.9497]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2386, 0.7614],\n",
            "        [0.1145, 0.8855]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1330, 0.8670],\n",
            "        [0.1344, 0.8656]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2190, 0.7810],\n",
            "        [0.5046, 0.4954]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1832, 0.8168],\n",
            "        [0.1215, 0.8785]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0847, 0.9153],\n",
            "        [0.1575, 0.8425]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1588, 0.8412],\n",
            "        [0.0396, 0.9604]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2791, 0.7209],\n",
            "        [0.2137, 0.7863]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0643, 0.9357],\n",
            "        [0.2463, 0.7537]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1293, 0.8707],\n",
            "        [0.0664, 0.9336]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1710, 0.8290],\n",
            "        [0.0781, 0.9219]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0852, 0.9148],\n",
            "        [0.1020, 0.8980]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1451, 0.8549],\n",
            "        [0.1455, 0.8545]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0652, 0.9348],\n",
            "        [0.3353, 0.6647]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0542, 0.9458],\n",
            "        [0.0469, 0.9531]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1524, 0.8476],\n",
            "        [0.0887, 0.9113]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2164, 0.7836],\n",
            "        [0.0496, 0.9504]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1177, 0.8823],\n",
            "        [0.1855, 0.8145]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1616, 0.8384],\n",
            "        [0.0477, 0.9523]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0398, 0.9602],\n",
            "        [0.0170, 0.9830]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0598, 0.9402],\n",
            "        [0.0407, 0.9593]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0431, 0.9569],\n",
            "        [0.0460, 0.9540]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4002, 0.5998]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3293, 0.6707],\n",
            "        [0.0646, 0.9354]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1288, 0.8712],\n",
            "        [0.0428, 0.9572]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0592, 0.9408],\n",
            "        [0.0616, 0.9384]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2362, 0.7638],\n",
            "        [0.0858, 0.9142]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5103, 0.4897],\n",
            "        [0.0307, 0.9693]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0395, 0.9605],\n",
            "        [0.1021, 0.8979]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0528, 0.9472],\n",
            "        [0.1740, 0.8260]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0846, 0.9154],\n",
            "        [0.0455, 0.9545]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2146, 0.7854],\n",
            "        [0.1419, 0.8581]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1718, 0.8282],\n",
            "        [0.1757, 0.8243]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1566, 0.8434],\n",
            "        [0.1375, 0.8625]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0859, 0.9141],\n",
            "        [0.2158, 0.7842]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0471, 0.9529],\n",
            "        [0.2387, 0.7613]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0443, 0.9557],\n",
            "        [0.2115, 0.7885]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4642, 0.5358],\n",
            "        [0.0624, 0.9376]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2346, 0.7654],\n",
            "        [0.1166, 0.8834]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1120, 0.8880],\n",
            "        [0.0624, 0.9376]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2133, 0.7867],\n",
            "        [0.1468, 0.8532]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1396, 0.8604],\n",
            "        [0.2455, 0.7545]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0734, 0.9266],\n",
            "        [0.3316, 0.6684]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0784, 0.9216],\n",
            "        [0.0655, 0.9345]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4264, 0.5736],\n",
            "        [0.5806, 0.4194]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1258, 0.8742],\n",
            "        [0.0370, 0.9630]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3866, 0.6134],\n",
            "        [0.1563, 0.8437]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0463, 0.9537],\n",
            "        [0.3143, 0.6857]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0651, 0.9349],\n",
            "        [0.0317, 0.9683]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0773, 0.9227],\n",
            "        [0.0470, 0.9530]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0827, 0.9173],\n",
            "        [0.1377, 0.8623]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1266, 0.8734],\n",
            "        [0.1163, 0.8837]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0809, 0.9191],\n",
            "        [0.0945, 0.9055]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3269, 0.6731],\n",
            "        [0.0873, 0.9127]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1601, 0.8399],\n",
            "        [0.2425, 0.7575]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1321, 0.8679],\n",
            "        [0.0531, 0.9469]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1428, 0.8572],\n",
            "        [0.1360, 0.8640]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1109, 0.8891],\n",
            "        [0.0189, 0.9811]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1777, 0.8223],\n",
            "        [0.1907, 0.8093]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0830, 0.9170],\n",
            "        [0.1786, 0.8214]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1029, 0.8971],\n",
            "        [0.0430, 0.9570]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0331, 0.9669],\n",
            "        [0.2807, 0.7193]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1437, 0.8563],\n",
            "        [0.4094, 0.5906]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0155, 0.9845],\n",
            "        [0.0389, 0.9611]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2700, 0.7300]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0388, 0.9612],\n",
            "        [0.1607, 0.8393]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1424, 0.8576],\n",
            "        [0.1161, 0.8839]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1393, 0.8607],\n",
            "        [0.4303, 0.5697]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0580, 0.9420],\n",
            "        [0.4118, 0.5882]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1379, 0.8621],\n",
            "        [0.2122, 0.7878]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0384, 0.9616],\n",
            "        [0.0414, 0.9586]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0835, 0.9165],\n",
            "        [0.2731, 0.7269]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0476, 0.9524],\n",
            "        [0.2476, 0.7524]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3329, 0.6671],\n",
            "        [0.1270, 0.8730]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0472, 0.9528],\n",
            "        [0.0792, 0.9208]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2907, 0.7093],\n",
            "        [0.1136, 0.8864]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0961, 0.9039],\n",
            "        [0.2148, 0.7852]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0473, 0.9527],\n",
            "        [0.0436, 0.9564]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0683, 0.9317],\n",
            "        [0.1768, 0.8232]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3482, 0.6518],\n",
            "        [0.1403, 0.8597]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1529, 0.8471],\n",
            "        [0.1734, 0.8266]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0385, 0.9615],\n",
            "        [0.1836, 0.8164]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1436, 0.8564],\n",
            "        [0.0670, 0.9330]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2407, 0.7593],\n",
            "        [0.0909, 0.9091]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0562, 0.9438],\n",
            "        [0.2568, 0.7432]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0842, 0.9158],\n",
            "        [0.0862, 0.9138]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1584, 0.8416],\n",
            "        [0.0158, 0.9842]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1136, 0.8864],\n",
            "        [0.1301, 0.8699]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1182, 0.8818],\n",
            "        [0.1022, 0.8978]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0299, 0.9701],\n",
            "        [0.3232, 0.6768]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1473, 0.8527],\n",
            "        [0.4708, 0.5292]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0191, 0.9809],\n",
            "        [0.1400, 0.8600]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0846, 0.9154],\n",
            "        [0.1905, 0.8095]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0423, 0.9577],\n",
            "        [0.0330, 0.9670]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2325, 0.7675],\n",
            "        [0.1037, 0.8963]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2156, 0.7844],\n",
            "        [0.5105, 0.4895]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0805, 0.9195],\n",
            "        [0.3268, 0.6732]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1316, 0.8684],\n",
            "        [0.0807, 0.9193]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3869, 0.6131],\n",
            "        [0.2116, 0.7884]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5865, 0.4135],\n",
            "        [0.1533, 0.8467]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0601, 0.9399],\n",
            "        [0.1679, 0.8321]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0423, 0.9577],\n",
            "        [0.1252, 0.8748]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0552, 0.9448],\n",
            "        [0.0500, 0.9500]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0596, 0.9404],\n",
            "        [0.1730, 0.8270]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0307, 0.9693],\n",
            "        [0.2369, 0.7631]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0773, 0.9227],\n",
            "        [0.0617, 0.9383]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0713, 0.9287]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1348, 0.8652],\n",
            "        [0.0323, 0.9677]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0598, 0.9402],\n",
            "        [0.2277, 0.7723]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3847, 0.6153],\n",
            "        [0.2096, 0.7904]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0797, 0.9203],\n",
            "        [0.0280, 0.9720]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0434, 0.9566],\n",
            "        [0.2419, 0.7581]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0549, 0.9451],\n",
            "        [0.1428, 0.8572]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0179, 0.9821],\n",
            "        [0.0143, 0.9857]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1645, 0.8355],\n",
            "        [0.2232, 0.7768]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5813, 0.4187],\n",
            "        [0.0800, 0.9200]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5043, 0.4957],\n",
            "        [0.0541, 0.9459]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1559, 0.8441],\n",
            "        [0.0698, 0.9302]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0409, 0.9591],\n",
            "        [0.2803, 0.7197]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0399, 0.9601],\n",
            "        [0.2328, 0.7672]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0737, 0.9263],\n",
            "        [0.1095, 0.8905]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0455, 0.9545],\n",
            "        [0.0785, 0.9215]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1725, 0.8275],\n",
            "        [0.1510, 0.8490]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0521, 0.9479],\n",
            "        [0.1114, 0.8886]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3317, 0.6683],\n",
            "        [0.0971, 0.9029]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0767, 0.9233],\n",
            "        [0.1324, 0.8676]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0851, 0.9149],\n",
            "        [0.2153, 0.7847]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3250, 0.6750],\n",
            "        [0.1250, 0.8750]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1632, 0.8368],\n",
            "        [0.0302, 0.9698]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1233, 0.8767],\n",
            "        [0.1007, 0.8993]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0635, 0.9365],\n",
            "        [0.2092, 0.7908]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0363, 0.9637],\n",
            "        [0.0480, 0.9520]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0600, 0.9400],\n",
            "        [0.1307, 0.8693]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0363, 0.9637],\n",
            "        [0.1185, 0.8815]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0891, 0.9109],\n",
            "        [0.1378, 0.8622]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1406, 0.8594],\n",
            "        [0.3265, 0.6735]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0793, 0.9207],\n",
            "        [0.1334, 0.8666]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0767, 0.9233],\n",
            "        [0.4139, 0.5861]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0339, 0.9661],\n",
            "        [0.1684, 0.8316]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0403, 0.9597],\n",
            "        [0.1298, 0.8702]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1683, 0.8317],\n",
            "        [0.2469, 0.7531]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1524, 0.8476],\n",
            "        [0.1064, 0.8936]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1336, 0.8664],\n",
            "        [0.0649, 0.9351]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0585, 0.9415],\n",
            "        [0.3162, 0.6838]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0446, 0.9554],\n",
            "        [0.4315, 0.5685]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2148, 0.7852],\n",
            "        [0.1903, 0.8097]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0399, 0.9601],\n",
            "        [0.0792, 0.9208]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1147, 0.8853],\n",
            "        [0.4730, 0.5270]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2718, 0.7282]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2146, 0.7854],\n",
            "        [0.0482, 0.9518]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1520, 0.8480],\n",
            "        [0.3161, 0.6839]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4205, 0.5795],\n",
            "        [0.2343, 0.7657]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0803, 0.9197],\n",
            "        [0.2489, 0.7511]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0812, 0.9188],\n",
            "        [0.0393, 0.9607]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1531, 0.8469],\n",
            "        [0.3859, 0.6141]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1317, 0.8683],\n",
            "        [0.0769, 0.9231]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0337, 0.9663],\n",
            "        [0.0316, 0.9684]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3372, 0.6628],\n",
            "        [0.0522, 0.9478]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1415, 0.8585],\n",
            "        [0.0888, 0.9112]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0590, 0.9410],\n",
            "        [0.0445, 0.9555]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0436, 0.9564],\n",
            "        [0.1299, 0.8701]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1685, 0.8315],\n",
            "        [0.0512, 0.9488]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1625, 0.8375],\n",
            "        [0.1584, 0.8416]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0358, 0.9642],\n",
            "        [0.0382, 0.9618]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1414, 0.8586],\n",
            "        [0.1028, 0.8972]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1106, 0.8894],\n",
            "        [0.2065, 0.7935]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5852, 0.4148],\n",
            "        [0.2127, 0.7873]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0619, 0.9381],\n",
            "        [0.1162, 0.8838]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0717, 0.9283],\n",
            "        [0.3267, 0.6733]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0958, 0.9042],\n",
            "        [0.1320, 0.8680]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0995, 0.9005],\n",
            "        [0.0351, 0.9649]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1318, 0.8682],\n",
            "        [0.0172, 0.9828]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2621, 0.7379],\n",
            "        [0.4215, 0.5785]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1087, 0.8913],\n",
            "        [0.1080, 0.8920]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0761, 0.9239],\n",
            "        [0.0387, 0.9613]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1218, 0.8782],\n",
            "        [0.0619, 0.9381]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1371, 0.8629],\n",
            "        [0.0286, 0.9714]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0390, 0.9610],\n",
            "        [0.0760, 0.9240]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0521, 0.9479],\n",
            "        [0.2233, 0.7767]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4655, 0.5345],\n",
            "        [0.0266, 0.9734]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0591, 0.9409],\n",
            "        [0.1693, 0.8307]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0410, 0.9590],\n",
            "        [0.1842, 0.8158]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0751, 0.9249],\n",
            "        [0.0552, 0.9448]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2357, 0.7643],\n",
            "        [0.1572, 0.8428]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2210, 0.7790],\n",
            "        [0.1202, 0.8798]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0659, 0.9341],\n",
            "        [0.0830, 0.9170]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1637, 0.8363],\n",
            "        [0.0128, 0.9872]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1288, 0.8712],\n",
            "        [0.2827, 0.7173]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2041, 0.7959],\n",
            "        [0.1269, 0.8731]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5098, 0.4902],\n",
            "        [0.0726, 0.9274]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3203, 0.6797]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5874, 0.4126],\n",
            "        [0.1290, 0.8710]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1571, 0.8429],\n",
            "        [0.0423, 0.9577]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0382, 0.9618],\n",
            "        [0.2371, 0.7629]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0993, 0.9007],\n",
            "        [0.0520, 0.9480]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2164, 0.7836],\n",
            "        [0.1578, 0.8422]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0767, 0.9233],\n",
            "        [0.1029, 0.8971]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2134, 0.7866],\n",
            "        [0.0419, 0.9581]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0444, 0.9556],\n",
            "        [0.4226, 0.5774]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1306, 0.8694],\n",
            "        [0.0175, 0.9825]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0364, 0.9636],\n",
            "        [0.2953, 0.7047]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0474, 0.9526],\n",
            "        [0.1366, 0.8634]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0785, 0.9215],\n",
            "        [0.1134, 0.8866]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0393, 0.9607],\n",
            "        [0.3210, 0.6790]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0874, 0.9126],\n",
            "        [0.1905, 0.8095]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2318, 0.7682],\n",
            "        [0.1412, 0.8588]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0909, 0.9091],\n",
            "        [0.0788, 0.9212]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0519, 0.9481],\n",
            "        [0.1188, 0.8812]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0748, 0.9252],\n",
            "        [0.2744, 0.7256]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0544, 0.9456],\n",
            "        [0.0588, 0.9412]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1153, 0.8847],\n",
            "        [0.0297, 0.9703]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0779, 0.9221],\n",
            "        [0.2412, 0.7588]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0134, 0.9866],\n",
            "        [0.1767, 0.8233]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0342, 0.9658],\n",
            "        [0.1358, 0.8642]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5339, 0.4661],\n",
            "        [0.0625, 0.9375]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0606, 0.9394],\n",
            "        [0.1142, 0.8858]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0643, 0.9357],\n",
            "        [0.4399, 0.5601]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3990, 0.6010],\n",
            "        [0.0816, 0.9184]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1469, 0.8531],\n",
            "        [0.0845, 0.9155]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0365, 0.9635],\n",
            "        [0.2136, 0.7864]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3492, 0.6508],\n",
            "        [0.3347, 0.6653]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2632, 0.7368],\n",
            "        [0.0394, 0.9606]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0665, 0.9335],\n",
            "        [0.1489, 0.8511]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0795, 0.9205],\n",
            "        [0.1771, 0.8229]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1602, 0.8398],\n",
            "        [0.0332, 0.9668]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4908, 0.5092],\n",
            "        [0.1045, 0.8955]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1555, 0.8445],\n",
            "        [0.1678, 0.8322]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0693, 0.9307],\n",
            "        [0.1346, 0.8654]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1300, 0.8700],\n",
            "        [0.0384, 0.9616]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0286, 0.9714],\n",
            "        [0.3596, 0.6404]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1751, 0.8249],\n",
            "        [0.2088, 0.7912]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1278, 0.8722],\n",
            "        [0.1423, 0.8577]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2363, 0.7637]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4388, 0.5612],\n",
            "        [0.2349, 0.7651]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1342, 0.8658],\n",
            "        [0.0534, 0.9466]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0739, 0.9261],\n",
            "        [0.3048, 0.6952]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0637, 0.9363],\n",
            "        [0.0291, 0.9709]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0274, 0.9726],\n",
            "        [0.0439, 0.9561]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1111, 0.8889],\n",
            "        [0.1555, 0.8445]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3331, 0.6669],\n",
            "        [0.1266, 0.8734]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1411, 0.8589],\n",
            "        [0.0176, 0.9824]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0447, 0.9553],\n",
            "        [0.0320, 0.9680]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0369, 0.9631],\n",
            "        [0.1135, 0.8865]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1390, 0.8610],\n",
            "        [0.1443, 0.8557]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1064, 0.8936],\n",
            "        [0.0531, 0.9469]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0672, 0.9328],\n",
            "        [0.0327, 0.9673]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2231, 0.7769],\n",
            "        [0.0647, 0.9353]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0876, 0.9124],\n",
            "        [0.1260, 0.8740]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0876, 0.9124],\n",
            "        [0.1367, 0.8633]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0615, 0.9385],\n",
            "        [0.0569, 0.9431]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1636, 0.8364],\n",
            "        [0.1649, 0.8351]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4410, 0.5590],\n",
            "        [0.1137, 0.8863]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0806, 0.9194],\n",
            "        [0.0466, 0.9534]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1788, 0.8212],\n",
            "        [0.0375, 0.9625]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1739, 0.8261],\n",
            "        [0.2214, 0.7786]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1484, 0.8516],\n",
            "        [0.5450, 0.4550]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1662, 0.8338],\n",
            "        [0.1729, 0.8271]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1179, 0.8821],\n",
            "        [0.0785, 0.9215]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1962, 0.8038],\n",
            "        [0.3616, 0.6384]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0612, 0.9388],\n",
            "        [0.0364, 0.9636]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1322, 0.8678],\n",
            "        [0.0759, 0.9241]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4916, 0.5084],\n",
            "        [0.0377, 0.9623]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0810, 0.9190],\n",
            "        [0.2337, 0.7663]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0433, 0.9567],\n",
            "        [0.0127, 0.9873]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0380, 0.9620],\n",
            "        [0.0495, 0.9505]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2056, 0.7944],\n",
            "        [0.1528, 0.8472]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2436, 0.7564],\n",
            "        [0.6108, 0.3892]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3215, 0.6785],\n",
            "        [0.0778, 0.9222]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2108, 0.7892],\n",
            "        [0.1045, 0.8955]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3483, 0.6517],\n",
            "        [0.2752, 0.7248]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3943, 0.6057],\n",
            "        [0.1309, 0.8691]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0381, 0.9619],\n",
            "        [0.2584, 0.7416]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1314, 0.8686],\n",
            "        [0.0999, 0.9001]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0815, 0.9185],\n",
            "        [0.0749, 0.9251]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2354, 0.7646]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2087, 0.7913],\n",
            "        [0.1596, 0.8404]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0377, 0.9623],\n",
            "        [0.1503, 0.8497]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0646, 0.9354],\n",
            "        [0.2333, 0.7667]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0360, 0.9640],\n",
            "        [0.2168, 0.7832]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0403, 0.9597],\n",
            "        [0.1117, 0.8883]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0496, 0.9504],\n",
            "        [0.2519, 0.7481]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4309, 0.5691],\n",
            "        [0.0304, 0.9696]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2666, 0.7334],\n",
            "        [0.0423, 0.9577]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1333, 0.8667],\n",
            "        [0.0769, 0.9231]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0794, 0.9206],\n",
            "        [0.0416, 0.9584]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0437, 0.9563],\n",
            "        [0.1249, 0.8751]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4271, 0.5729],\n",
            "        [0.1008, 0.8992]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0529, 0.9471],\n",
            "        [0.2359, 0.7641]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0345, 0.9655],\n",
            "        [0.2219, 0.7781]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2184, 0.7816],\n",
            "        [0.0584, 0.9416]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1710, 0.8290],\n",
            "        [0.0755, 0.9245]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1286, 0.8714],\n",
            "        [0.0272, 0.9728]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3886, 0.6114],\n",
            "        [0.1001, 0.8999]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1104, 0.8896],\n",
            "        [0.1864, 0.8136]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0303, 0.9697],\n",
            "        [0.3437, 0.6563]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2008, 0.7992],\n",
            "        [0.0165, 0.9835]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0736, 0.9264],\n",
            "        [0.0258, 0.9742]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3292, 0.6708],\n",
            "        [0.0620, 0.9380]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1258, 0.8742],\n",
            "        [0.1619, 0.8381]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1085, 0.8915],\n",
            "        [0.0721, 0.9279]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0344, 0.9656],\n",
            "        [0.1429, 0.8571]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1390, 0.8610],\n",
            "        [0.1287, 0.8713]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6082, 0.3918],\n",
            "        [0.0361, 0.9639]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5367, 0.4633],\n",
            "        [0.0974, 0.9026]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1217, 0.8783],\n",
            "        [0.0835, 0.9165]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3031, 0.6969],\n",
            "        [0.1675, 0.8325]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0570, 0.9430],\n",
            "        [0.0610, 0.9390]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1500, 0.8500],\n",
            "        [0.3482, 0.6518]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0696, 0.9304],\n",
            "        [0.1235, 0.8765]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1616, 0.8384],\n",
            "        [0.0721, 0.9279]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1073, 0.8927],\n",
            "        [0.0334, 0.9666]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0114, 0.9886],\n",
            "        [0.2257, 0.7743]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4867, 0.5133],\n",
            "        [0.1324, 0.8676]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3192, 0.6808],\n",
            "        [0.0509, 0.9491]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0851, 0.9149],\n",
            "        [0.0742, 0.9258]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0466, 0.9534],\n",
            "        [0.1571, 0.8429]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1362, 0.8638]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0737, 0.9263],\n",
            "        [0.2078, 0.7922]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0571, 0.9429],\n",
            "        [0.1251, 0.8749]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0844, 0.9156],\n",
            "        [0.0754, 0.9246]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1867, 0.8133],\n",
            "        [0.1608, 0.8392]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4311, 0.5689],\n",
            "        [0.3167, 0.6833]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0335, 0.9665],\n",
            "        [0.0393, 0.9607]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0704, 0.9296],\n",
            "        [0.1074, 0.8926]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1014, 0.8986],\n",
            "        [0.0484, 0.9516]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2219, 0.7781],\n",
            "        [0.1301, 0.8699]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1718, 0.8282],\n",
            "        [0.1047, 0.8953]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1474, 0.8526],\n",
            "        [0.3443, 0.6557]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0326, 0.9674],\n",
            "        [0.0352, 0.9648]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0340, 0.9660],\n",
            "        [0.1218, 0.8782]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0975, 0.9025],\n",
            "        [0.0601, 0.9399]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2165, 0.7835],\n",
            "        [0.0406, 0.9594]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6070, 0.3930],\n",
            "        [0.5368, 0.4632]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1089, 0.8911],\n",
            "        [0.1092, 0.8908]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0784, 0.9216],\n",
            "        [0.0158, 0.9842]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0291, 0.9709],\n",
            "        [0.2191, 0.7809]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2668, 0.7332],\n",
            "        [0.0958, 0.9042]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0409, 0.9591],\n",
            "        [0.1330, 0.8670]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0493, 0.9507],\n",
            "        [0.2355, 0.7645]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0358, 0.9642],\n",
            "        [0.3271, 0.6729]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0339, 0.9661],\n",
            "        [0.0516, 0.9484]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1654, 0.8346],\n",
            "        [0.1235, 0.8765]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1418, 0.8582],\n",
            "        [0.0294, 0.9706]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0718, 0.9282],\n",
            "        [0.4365, 0.5635]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0577, 0.9423],\n",
            "        [0.0618, 0.9382]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0427, 0.9573],\n",
            "        [0.1591, 0.8409]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1198, 0.8802],\n",
            "        [0.1998, 0.8002]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0457, 0.9543],\n",
            "        [0.0824, 0.9176]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1275, 0.8725],\n",
            "        [0.1480, 0.8520]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3906, 0.6094],\n",
            "        [0.1558, 0.8442]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0108, 0.9892],\n",
            "        [0.2306, 0.7694]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1272, 0.8728],\n",
            "        [0.2535, 0.7465]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3466, 0.6534],\n",
            "        [0.0761, 0.9239]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0259, 0.9741],\n",
            "        [0.3026, 0.6974]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2217, 0.7783],\n",
            "        [0.4863, 0.5137]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1539, 0.8461],\n",
            "        [0.0611, 0.9389]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1382, 0.8618],\n",
            "        [0.1344, 0.8656]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0248, 0.9752],\n",
            "        [0.0698, 0.9302]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0677, 0.9323]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0249, 0.9751],\n",
            "        [0.0413, 0.9587]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0360, 0.9640],\n",
            "        [0.1067, 0.8933]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0325, 0.9675],\n",
            "        [0.1747, 0.8253]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1659, 0.8341],\n",
            "        [0.3920, 0.6080]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1233, 0.8767],\n",
            "        [0.0778, 0.9222]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0328, 0.9672],\n",
            "        [0.0983, 0.9017]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1234, 0.8766],\n",
            "        [0.0161, 0.9839]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4353, 0.5647],\n",
            "        [0.0291, 0.9709]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0853, 0.9147],\n",
            "        [0.0615, 0.9385]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0482, 0.9518],\n",
            "        [0.0717, 0.9283]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0449, 0.9551],\n",
            "        [0.1316, 0.8684]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1989, 0.8011],\n",
            "        [0.0335, 0.9665]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0415, 0.9585],\n",
            "        [0.2645, 0.7355]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0714, 0.9286],\n",
            "        [0.0266, 0.9734]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3244, 0.6756],\n",
            "        [0.1408, 0.8592]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1396, 0.8604],\n",
            "        [0.0584, 0.9416]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2378, 0.7622],\n",
            "        [0.3606, 0.6394]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1482, 0.8518],\n",
            "        [0.2335, 0.7665]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1548, 0.8452],\n",
            "        [0.0110, 0.9890]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4989, 0.5011],\n",
            "        [0.0633, 0.9367]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0835, 0.9165],\n",
            "        [0.2119, 0.7881]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1132, 0.8868],\n",
            "        [0.1581, 0.8419]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2814, 0.7186],\n",
            "        [0.1237, 0.8763]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0357, 0.9643],\n",
            "        [0.0822, 0.9178]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1637, 0.8363],\n",
            "        [0.0746, 0.9254]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0305, 0.9695],\n",
            "        [0.0621, 0.9379]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0508, 0.9492],\n",
            "        [0.0429, 0.9571]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0694, 0.9306],\n",
            "        [0.1052, 0.8948]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6224, 0.3776],\n",
            "        [0.1257, 0.8743]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0706, 0.9294],\n",
            "        [0.1094, 0.8906]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1301, 0.8699],\n",
            "        [0.5531, 0.4469]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1370, 0.8630],\n",
            "        [0.3563, 0.6437]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2269, 0.7731],\n",
            "        [0.0748, 0.9252]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0587, 0.9413],\n",
            "        [0.2244, 0.7756]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2265, 0.7735],\n",
            "        [0.3296, 0.6704]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1290, 0.8710],\n",
            "        [0.0977, 0.9023]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1484, 0.8516],\n",
            "        [0.1542, 0.8458]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1639, 0.8361],\n",
            "        [0.3131, 0.6869]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1053, 0.8947],\n",
            "        [0.0344, 0.9656]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0389, 0.9611],\n",
            "        [0.2229, 0.7771]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1893, 0.8107],\n",
            "        [0.4466, 0.5534]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0518, 0.9482]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0287, 0.9713],\n",
            "        [0.0517, 0.9483]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1536, 0.8464],\n",
            "        [0.3160, 0.6840]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4489, 0.5511],\n",
            "        [0.0853, 0.9147]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1209, 0.8791],\n",
            "        [0.2268, 0.7732]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1220, 0.8780],\n",
            "        [0.0973, 0.9027]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1249, 0.8751],\n",
            "        [0.0422, 0.9578]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0706, 0.9294],\n",
            "        [0.1816, 0.8184]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0605, 0.9395],\n",
            "        [0.2374, 0.7626]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1005, 0.8995],\n",
            "        [0.5611, 0.4389]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1131, 0.8869],\n",
            "        [0.0510, 0.9490]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1057, 0.8943],\n",
            "        [0.1323, 0.8677]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0434, 0.9566],\n",
            "        [0.0399, 0.9601]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1431, 0.8569],\n",
            "        [0.0163, 0.9837]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2298, 0.7702],\n",
            "        [0.0630, 0.9370]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2832, 0.7168],\n",
            "        [0.1331, 0.8669]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1553, 0.8447],\n",
            "        [0.1421, 0.8579]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2325, 0.7675],\n",
            "        [0.0306, 0.9694]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0321, 0.9679],\n",
            "        [0.3322, 0.6678]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2317, 0.7683],\n",
            "        [0.0250, 0.9750]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0104, 0.9896],\n",
            "        [0.1319, 0.8681]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0696, 0.9304],\n",
            "        [0.0471, 0.9529]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0350, 0.9650],\n",
            "        [0.5020, 0.4980]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0310, 0.9690],\n",
            "        [0.1595, 0.8405]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1483, 0.8517],\n",
            "        [0.0780, 0.9220]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3659, 0.6341],\n",
            "        [0.0403, 0.9597]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2656, 0.7344],\n",
            "        [0.2305, 0.7695]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0698, 0.9302],\n",
            "        [0.1661, 0.8339]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2112, 0.7888],\n",
            "        [0.1654, 0.8346]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1054, 0.8946],\n",
            "        [0.0573, 0.9427]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0405, 0.9595],\n",
            "        [0.0612, 0.9388]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0736, 0.9264],\n",
            "        [0.1222, 0.8778]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3269, 0.6731],\n",
            "        [0.1063, 0.8937]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6269, 0.3731],\n",
            "        [0.3937, 0.6063]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1503, 0.8497],\n",
            "        [0.0589, 0.9411]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1394, 0.8606],\n",
            "        [0.0355, 0.9645]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0715, 0.9285],\n",
            "        [0.0316, 0.9684]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0331, 0.9669],\n",
            "        [0.0677, 0.9323]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1073, 0.8927],\n",
            "        [0.1965, 0.8035]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0258, 0.9742],\n",
            "        [0.0796, 0.9204]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0819, 0.9181],\n",
            "        [0.4411, 0.5589]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1492, 0.8508],\n",
            "        [0.1923, 0.8077]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3655, 0.6345]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0700, 0.9300],\n",
            "        [0.1528, 0.8472]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1821, 0.8179],\n",
            "        [0.0100, 0.9900]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0157, 0.9843],\n",
            "        [0.0406, 0.9594]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0712, 0.9288],\n",
            "        [0.2263, 0.7737]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3264, 0.6736],\n",
            "        [0.0588, 0.9412]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1065, 0.8935],\n",
            "        [0.3288, 0.6712]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0297, 0.9703],\n",
            "        [0.0499, 0.9501]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2294, 0.7706],\n",
            "        [0.1884, 0.8116]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1465, 0.8535],\n",
            "        [0.0940, 0.9060]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4534, 0.5466],\n",
            "        [0.3563, 0.6437]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2249, 0.7751],\n",
            "        [0.2330, 0.7670]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0268, 0.9732],\n",
            "        [0.0796, 0.9204]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1023, 0.8977],\n",
            "        [0.0236, 0.9764]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0305, 0.9695],\n",
            "        [0.3898, 0.6102]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0393, 0.9607],\n",
            "        [0.1338, 0.8662]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0327, 0.9673],\n",
            "        [0.4910, 0.5090]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0817, 0.9183],\n",
            "        [0.1318, 0.8682]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1597, 0.8403],\n",
            "        [0.0996, 0.9004]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0532, 0.9468],\n",
            "        [0.3527, 0.6473]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0576, 0.9424],\n",
            "        [0.2614, 0.7386]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1008, 0.8992],\n",
            "        [0.0412, 0.9588]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0684, 0.9316],\n",
            "        [0.5448, 0.4552]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2498, 0.7502],\n",
            "        [0.0739, 0.9261]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0655, 0.9345],\n",
            "        [0.0623, 0.9377]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0476, 0.9524],\n",
            "        [0.1468, 0.8532]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0428, 0.9572],\n",
            "        [0.0761, 0.9239]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0566, 0.9434],\n",
            "        [0.1228, 0.8772]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1260, 0.8740],\n",
            "        [0.1150, 0.8850]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2029, 0.7971],\n",
            "        [0.1450, 0.8550]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1142, 0.8858],\n",
            "        [0.0318, 0.9682]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0301, 0.9699],\n",
            "        [0.1581, 0.8419]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3088, 0.6912],\n",
            "        [0.1227, 0.8773]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0387, 0.9613],\n",
            "        [0.0630, 0.9370]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1197, 0.8803],\n",
            "        [0.2136, 0.7864]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1320, 0.8680],\n",
            "        [0.0238, 0.9762]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0340, 0.9660],\n",
            "        [0.6167, 0.3833]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0579, 0.9421],\n",
            "        [0.1912, 0.8088]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1158, 0.8842],\n",
            "        [0.1428, 0.8572]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4223, 0.5777],\n",
            "        [0.1088, 0.8912]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0943, 0.9057],\n",
            "        [0.2245, 0.7755]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0354, 0.9646],\n",
            "        [0.1407, 0.8593]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0290, 0.9710]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0148, 0.9852],\n",
            "        [0.0565, 0.9435]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0229, 0.9771],\n",
            "        [0.2182, 0.7818]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1097, 0.8903],\n",
            "        [0.1598, 0.8402]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0479, 0.9521],\n",
            "        [0.5566, 0.4434]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0958, 0.9042],\n",
            "        [0.1436, 0.8564]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0708, 0.9292],\n",
            "        [0.3207, 0.6793]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0319, 0.9681],\n",
            "        [0.2070, 0.7930]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0596, 0.9404],\n",
            "        [0.1475, 0.8525]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2294, 0.7706],\n",
            "        [0.0843, 0.9157]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0929, 0.9071],\n",
            "        [0.2266, 0.7734]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1667, 0.8333],\n",
            "        [0.0304, 0.9696]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1359, 0.8641],\n",
            "        [0.0698, 0.9302]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2351, 0.7649],\n",
            "        [0.0450, 0.9550]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0348, 0.9652],\n",
            "        [0.0410, 0.9590]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0268, 0.9732],\n",
            "        [0.0682, 0.9318]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0502, 0.9498],\n",
            "        [0.5052, 0.4948]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1028, 0.8972],\n",
            "        [0.2743, 0.7257]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1403, 0.8597],\n",
            "        [0.0301, 0.9699]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3988, 0.6012],\n",
            "        [0.1305, 0.8695]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0578, 0.9422],\n",
            "        [0.0307, 0.9693]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3313, 0.6687],\n",
            "        [0.3713, 0.6287]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2840, 0.7160],\n",
            "        [0.1421, 0.8579]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2280, 0.7720],\n",
            "        [0.1198, 0.8802]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1563, 0.8437],\n",
            "        [0.0408, 0.9592]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3777, 0.6223],\n",
            "        [0.2337, 0.7663]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1290, 0.8710],\n",
            "        [0.0627, 0.9373]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1948, 0.8052],\n",
            "        [0.1827, 0.8173]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1059, 0.8941],\n",
            "        [0.1926, 0.8074]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0376, 0.9624],\n",
            "        [0.0786, 0.9214]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4407, 0.5593],\n",
            "        [0.1201, 0.8799]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0403, 0.9597],\n",
            "        [0.1060, 0.8940]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1246, 0.8754],\n",
            "        [0.6370, 0.3630]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0093, 0.9907],\n",
            "        [0.0660, 0.9340]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1030, 0.8970],\n",
            "        [0.0691, 0.9309]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4643, 0.5357],\n",
            "        [0.0786, 0.9214]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0294, 0.9706],\n",
            "        [0.1498, 0.8502]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0348, 0.9652],\n",
            "        [0.0826, 0.9174]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1510, 0.8490],\n",
            "        [0.0583, 0.9417]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1224, 0.8776],\n",
            "        [0.0664, 0.9336]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1314, 0.8686],\n",
            "        [0.0250, 0.9750]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0405, 0.9595],\n",
            "        [0.3334, 0.6666]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1507, 0.8493]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1506, 0.8494],\n",
            "        [0.0092, 0.9908]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3981, 0.6019],\n",
            "        [0.0266, 0.9734]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1625, 0.8375],\n",
            "        [0.4435, 0.5565]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0573, 0.9427],\n",
            "        [0.0400, 0.9600]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3314, 0.6686],\n",
            "        [0.1066, 0.8934]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0296, 0.9704],\n",
            "        [0.0340, 0.9660]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0701, 0.9299],\n",
            "        [0.1277, 0.8723]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1534, 0.8466],\n",
            "        [0.2247, 0.7753]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0980, 0.9020],\n",
            "        [0.2082, 0.7918]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0774, 0.9226],\n",
            "        [0.1926, 0.8074]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5029, 0.4971],\n",
            "        [0.0796, 0.9204]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2280, 0.7720],\n",
            "        [0.1218, 0.8782]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0664, 0.9336],\n",
            "        [0.0145, 0.9855]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3581, 0.6419],\n",
            "        [0.1868, 0.8132]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2158, 0.7842],\n",
            "        [0.1430, 0.8570]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0736, 0.9264],\n",
            "        [0.0420, 0.9580]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6235, 0.3765],\n",
            "        [0.1619, 0.8381]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0272, 0.9728],\n",
            "        [0.0803, 0.9197]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2265, 0.7735],\n",
            "        [0.1321, 0.8679]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0633, 0.9367],\n",
            "        [0.2255, 0.7745]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0390, 0.9610],\n",
            "        [0.0455, 0.9545]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3151, 0.6849],\n",
            "        [0.0565, 0.9435]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2188, 0.7812],\n",
            "        [0.1418, 0.8582]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0217, 0.9783],\n",
            "        [0.0227, 0.9773]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0598, 0.9402],\n",
            "        [0.1231, 0.8769]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1109, 0.8891],\n",
            "        [0.0462, 0.9538]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1276, 0.8724],\n",
            "        [0.1261, 0.8739]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0306, 0.9694],\n",
            "        [0.0514, 0.9486]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3568, 0.6432],\n",
            "        [0.0604, 0.9396]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2604, 0.7396],\n",
            "        [0.4485, 0.5515]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0279, 0.9721],\n",
            "        [0.1213, 0.8787]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0661, 0.9339],\n",
            "        [0.0881, 0.9119]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1699, 0.8301],\n",
            "        [0.1440, 0.8560]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1143, 0.8857],\n",
            "        [0.0976, 0.9024]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2564, 0.7436],\n",
            "        [0.0272, 0.9728]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0327, 0.9673],\n",
            "        [0.0338, 0.9662]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1439, 0.8561],\n",
            "        [0.0546, 0.9454]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0382, 0.9618],\n",
            "        [0.0378, 0.9622]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0587, 0.9413],\n",
            "        [0.1006, 0.8994]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3232, 0.6768],\n",
            "        [0.0982, 0.9018]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5641, 0.4359],\n",
            "        [0.1140, 0.8860]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1094, 0.8906]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1574, 0.8426],\n",
            "        [0.0331, 0.9669]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3248, 0.6752],\n",
            "        [0.1357, 0.8643]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1466, 0.8534],\n",
            "        [0.0630, 0.9370]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0899, 0.9101],\n",
            "        [0.0306, 0.9694]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1861, 0.8139],\n",
            "        [0.5686, 0.4314]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0380, 0.9620],\n",
            "        [0.0287, 0.9713]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1021, 0.8979],\n",
            "        [0.1437, 0.8563]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0548, 0.9452],\n",
            "        [0.2056, 0.7944]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0617, 0.9383],\n",
            "        [0.2270, 0.7730]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3900, 0.6100],\n",
            "        [0.1134, 0.8866]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6349, 0.3651],\n",
            "        [0.2314, 0.7686]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1237, 0.8763],\n",
            "        [0.0786, 0.9214]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0974, 0.9026],\n",
            "        [0.0460, 0.9540]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0268, 0.9732],\n",
            "        [0.1784, 0.8216]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1150, 0.8850],\n",
            "        [0.4335, 0.5665]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0222, 0.9778],\n",
            "        [0.0244, 0.9756]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0478, 0.9522],\n",
            "        [0.0686, 0.9314]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1278, 0.8722],\n",
            "        [0.1019, 0.8981]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3769, 0.6231],\n",
            "        [0.0592, 0.9408]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0422, 0.9578],\n",
            "        [0.1474, 0.8526]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1222, 0.8778],\n",
            "        [0.0326, 0.9674]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3673, 0.6327],\n",
            "        [0.0144, 0.9856]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0773, 0.9227],\n",
            "        [0.2772, 0.7228]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0647, 0.9353],\n",
            "        [0.0568, 0.9432]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1339, 0.8661],\n",
            "        [0.0841, 0.9159]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0544, 0.9456],\n",
            "        [0.0975, 0.9025]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5092, 0.4908],\n",
            "        [0.1385, 0.8615]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0348, 0.9652],\n",
            "        [0.0991, 0.9009]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0648, 0.9352],\n",
            "        [0.0376, 0.9624]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1161, 0.8839],\n",
            "        [0.0082, 0.9918]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0579, 0.9421],\n",
            "        [0.0378, 0.9622]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2199, 0.7801],\n",
            "        [0.0659, 0.9341]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2188, 0.7812],\n",
            "        [0.0271, 0.9729]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3224, 0.6776],\n",
            "        [0.1409, 0.8591]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1084, 0.8916],\n",
            "        [0.1403, 0.8597]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0370, 0.9630],\n",
            "        [0.1223, 0.8777]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1871, 0.8129],\n",
            "        [0.3282, 0.6718]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1432, 0.8568],\n",
            "        [0.0221, 0.9779]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2254, 0.7746],\n",
            "        [0.4611, 0.5389]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1633, 0.8367],\n",
            "        [0.2255, 0.7745]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2631, 0.7369],\n",
            "        [0.0270, 0.9730]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0725, 0.9275]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2251, 0.7749],\n",
            "        [0.3322, 0.6678]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0339, 0.9661],\n",
            "        [0.0758, 0.9242]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1461, 0.8539],\n",
            "        [0.3276, 0.6724]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0663, 0.9337],\n",
            "        [0.1147, 0.8853]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0583, 0.9417],\n",
            "        [0.0228, 0.9772]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0560, 0.9440],\n",
            "        [0.1676, 0.8324]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2760, 0.7240],\n",
            "        [0.3277, 0.6723]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0539, 0.9461],\n",
            "        [0.0463, 0.9537]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0328, 0.9672],\n",
            "        [0.2209, 0.7791]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1895, 0.8105],\n",
            "        [0.0081, 0.9919]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1020, 0.8980],\n",
            "        [0.0894, 0.9106]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0977, 0.9023],\n",
            "        [0.0482, 0.9518]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2069, 0.7931],\n",
            "        [0.2355, 0.7645]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3820, 0.6180],\n",
            "        [0.0297, 0.9703]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0222, 0.9778],\n",
            "        [0.1367, 0.8633]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0284, 0.9716],\n",
            "        [0.0542, 0.9458]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5090, 0.4910],\n",
            "        [0.1833, 0.8167]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1320, 0.8680],\n",
            "        [0.0599, 0.9401]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1282, 0.8718],\n",
            "        [0.0686, 0.9314]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1448, 0.8552],\n",
            "        [0.0652, 0.9348]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1584, 0.8416],\n",
            "        [0.1881, 0.8119]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0613, 0.9387],\n",
            "        [0.2333, 0.7667]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0382, 0.9618],\n",
            "        [0.0809, 0.9191]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0265, 0.9735],\n",
            "        [0.1361, 0.8639]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0272, 0.9728],\n",
            "        [0.0625, 0.9375]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6467, 0.3533],\n",
            "        [0.0986, 0.9014]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1139, 0.8861],\n",
            "        [0.1467, 0.8533]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0971, 0.9029],\n",
            "        [0.0373, 0.9627]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4396, 0.5604],\n",
            "        [0.1255, 0.8745]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1449, 0.8551],\n",
            "        [0.1059, 0.8941]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4758, 0.5242],\n",
            "        [0.1248, 0.8752]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0244, 0.9756],\n",
            "        [0.0646, 0.9354]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1446, 0.8554],\n",
            "        [0.1179, 0.8821]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0376, 0.9624],\n",
            "        [0.1125, 0.8875]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0145, 0.9855],\n",
            "        [0.3765, 0.6235]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1504, 0.8496],\n",
            "        [0.1239, 0.8761]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0284, 0.9716],\n",
            "        [0.5880, 0.4120]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2244, 0.7756],\n",
            "        [0.0421, 0.9579]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2803, 0.7197],\n",
            "        [0.0330, 0.9670]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3985, 0.6015],\n",
            "        [0.2314, 0.7686]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0386, 0.9614],\n",
            "        [0.0738, 0.9262]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0860, 0.9140]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0698, 0.9302],\n",
            "        [0.0374, 0.9626]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0284, 0.9716],\n",
            "        [0.1466, 0.8534]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1720, 0.8280],\n",
            "        [0.0144, 0.9856]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1000, 0.9000],\n",
            "        [0.0269, 0.9731]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0262, 0.9738],\n",
            "        [0.1498, 0.8502]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0287, 0.9713],\n",
            "        [0.0646, 0.9354]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3788, 0.6212],\n",
            "        [0.2356, 0.7644]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3319, 0.6681],\n",
            "        [0.1292, 0.8708]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0787, 0.9213],\n",
            "        [0.0422, 0.9578]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0569, 0.9431],\n",
            "        [0.1875, 0.8125]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1069, 0.8931],\n",
            "        [0.2832, 0.7168]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2403, 0.7597],\n",
            "        [0.6544, 0.3456]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1273, 0.8727],\n",
            "        [0.0369, 0.9631]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2249, 0.7751],\n",
            "        [0.0540, 0.9460]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2324, 0.7676],\n",
            "        [0.0490, 0.9510]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0629, 0.9371],\n",
            "        [0.0080, 0.9920]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0746, 0.9254],\n",
            "        [0.0334, 0.9666]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0813, 0.9187],\n",
            "        [0.1472, 0.8528]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2253, 0.7747],\n",
            "        [0.1239, 0.8761]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2358, 0.7642],\n",
            "        [0.4022, 0.5978]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1025, 0.8975],\n",
            "        [0.1591, 0.8409]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3350, 0.6650],\n",
            "        [0.1243, 0.8757]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5156, 0.4844],\n",
            "        [0.1148, 0.8852]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0614, 0.9386],\n",
            "        [0.0541, 0.9459]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0900, 0.9100],\n",
            "        [0.4758, 0.5242]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3878, 0.6122],\n",
            "        [0.1123, 0.8877]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0836, 0.9164],\n",
            "        [0.1465, 0.8535]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0295, 0.9705],\n",
            "        [0.0597, 0.9403]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0377, 0.9623],\n",
            "        [0.0989, 0.9011]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5823, 0.4177],\n",
            "        [0.1358, 0.8642]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0237, 0.9763],\n",
            "        [0.0665, 0.9335]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1158, 0.8842],\n",
            "        [0.1289, 0.8711]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2037, 0.7963],\n",
            "        [0.0220, 0.9780]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1404, 0.8596],\n",
            "        [0.2724, 0.7276]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1421, 0.8579],\n",
            "        [0.3415, 0.6585]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0453, 0.9547],\n",
            "        [0.0337, 0.9663]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0638, 0.9362],\n",
            "        [0.0577, 0.9423]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1141, 0.8859],\n",
            "        [0.0321, 0.9679]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1865, 0.8135],\n",
            "        [0.4409, 0.5591]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0218, 0.9782],\n",
            "        [0.0372, 0.9628]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0957, 0.9043],\n",
            "        [0.1386, 0.8614]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1920, 0.8080]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2817, 0.7183],\n",
            "        [0.1492, 0.8508]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0346, 0.9654],\n",
            "        [0.1467, 0.8533]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1127, 0.8873],\n",
            "        [0.0641, 0.9359]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0278, 0.9722],\n",
            "        [0.1477, 0.8523]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0324, 0.9676],\n",
            "        [0.1893, 0.8107]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0692, 0.9308],\n",
            "        [0.0370, 0.9630]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0423, 0.9577],\n",
            "        [0.2437, 0.7563]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0225, 0.9775],\n",
            "        [0.2105, 0.7895]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0496, 0.9504],\n",
            "        [0.0144, 0.9856]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0259, 0.9741],\n",
            "        [0.4072, 0.5928]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1451, 0.8549],\n",
            "        [0.0537, 0.9463]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1471, 0.8529],\n",
            "        [0.1203, 0.8797]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0582, 0.9418],\n",
            "        [0.0361, 0.9639]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0884, 0.9116],\n",
            "        [0.4059, 0.5941]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2313, 0.7687],\n",
            "        [0.0291, 0.9709]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0264, 0.9736],\n",
            "        [0.3627, 0.6373]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1395, 0.8605],\n",
            "        [0.1270, 0.8730]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5320, 0.4680],\n",
            "        [0.0637, 0.9363]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1048, 0.8952],\n",
            "        [0.0976, 0.9024]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0343, 0.9657],\n",
            "        [0.1201, 0.8799]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2426, 0.7574],\n",
            "        [0.1870, 0.8130]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0077, 0.9923],\n",
            "        [0.0229, 0.9771]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1144, 0.8856],\n",
            "        [0.0736, 0.9264]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0997, 0.9003],\n",
            "        [0.2300, 0.7700]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6020, 0.3980],\n",
            "        [0.1023, 0.8977]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0612, 0.9388],\n",
            "        [0.1576, 0.8424]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3436, 0.6564],\n",
            "        [0.0287, 0.9713]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0794, 0.9206],\n",
            "        [0.4503, 0.5497]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1299, 0.8701],\n",
            "        [0.2325, 0.7675]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4902, 0.5098],\n",
            "        [0.1483, 0.8517]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1432, 0.8568],\n",
            "        [0.3313, 0.6687]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0234, 0.9766],\n",
            "        [0.2897, 0.7103]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0371, 0.9629],\n",
            "        [0.3873, 0.6127]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0817, 0.9183],\n",
            "        [0.1235, 0.8765]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6640, 0.3360],\n",
            "        [0.0593, 0.9407]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1938, 0.8062],\n",
            "        [0.0668, 0.9332]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0629, 0.9371],\n",
            "        [0.1743, 0.8257]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1248, 0.8752],\n",
            "        [0.0452, 0.9548]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0880, 0.9120],\n",
            "        [0.1333, 0.8667]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0598, 0.9402],\n",
            "        [0.2306, 0.7694]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1080, 0.8920],\n",
            "        [0.0380, 0.9620]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0547, 0.9453]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2082, 0.7918],\n",
            "        [0.0273, 0.9727]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0480, 0.9520],\n",
            "        [0.0717, 0.9283]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1168, 0.8832],\n",
            "        [0.1231, 0.8769]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0073, 0.9927],\n",
            "        [0.0996, 0.9004]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0679, 0.9321],\n",
            "        [0.0219, 0.9781]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0541, 0.9459],\n",
            "        [0.0880, 0.9120]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2233, 0.7767],\n",
            "        [0.0560, 0.9440]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2368, 0.7632],\n",
            "        [0.2855, 0.7145]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1457, 0.8543],\n",
            "        [0.0337, 0.9663]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1451, 0.8549],\n",
            "        [0.1399, 0.8601]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4885, 0.5115],\n",
            "        [0.0782, 0.9218]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1279, 0.8721],\n",
            "        [0.0974, 0.9026]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1917, 0.8083],\n",
            "        [0.0450, 0.9550]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0229, 0.9771],\n",
            "        [0.3567, 0.6433]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1150, 0.8850],\n",
            "        [0.1409, 0.8591]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6658, 0.3342],\n",
            "        [0.1358, 0.8642]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1430, 0.8570],\n",
            "        [0.0804, 0.9196]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0328, 0.9672],\n",
            "        [0.0250, 0.9750]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0582, 0.9418],\n",
            "        [0.0279, 0.9721]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1086, 0.8914],\n",
            "        [0.3874, 0.6126]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0607, 0.9393],\n",
            "        [0.1227, 0.8773]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0361, 0.9639],\n",
            "        [0.6029, 0.3971]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0137, 0.9863],\n",
            "        [0.2314, 0.7686]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1839, 0.8161],\n",
            "        [0.0355, 0.9645]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0339, 0.9661],\n",
            "        [0.0401, 0.9599]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0212, 0.9788],\n",
            "        [0.1453, 0.8547]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1120, 0.8880],\n",
            "        [0.5280, 0.4720]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0587, 0.9413],\n",
            "        [0.1324, 0.8676]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4002, 0.5998],\n",
            "        [0.1239, 0.8761]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0928, 0.9072],\n",
            "        [0.0612, 0.9388]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0501, 0.9499],\n",
            "        [0.0580, 0.9420]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2410, 0.7590],\n",
            "        [0.0615, 0.9385]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1536, 0.8464],\n",
            "        [0.2215, 0.7785]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4443, 0.5557],\n",
            "        [0.2810, 0.7190]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0234, 0.9766],\n",
            "        [0.3988, 0.6012]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3280, 0.6720],\n",
            "        [0.0307, 0.9693]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0843, 0.9157],\n",
            "        [0.1486, 0.8514]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0988, 0.9012],\n",
            "        [0.1884, 0.8116]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3381, 0.6619],\n",
            "        [0.1712, 0.8288]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0645, 0.9355],\n",
            "        [0.1077, 0.8923]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2287, 0.7713],\n",
            "        [0.0270, 0.9730]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0368, 0.9632]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1066, 0.8934],\n",
            "        [0.0798, 0.9202]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1349, 0.8651],\n",
            "        [0.3390, 0.6610]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0613, 0.9387],\n",
            "        [0.0777, 0.9223]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0439, 0.9561],\n",
            "        [0.1240, 0.8760]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0236, 0.9764],\n",
            "        [0.0580, 0.9420]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1311, 0.8689],\n",
            "        [0.0531, 0.9469]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1722, 0.8278],\n",
            "        [0.2060, 0.7940]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1453, 0.8547],\n",
            "        [0.2217, 0.7783]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0991, 0.9009],\n",
            "        [0.0211, 0.9789]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1905, 0.8095],\n",
            "        [0.4941, 0.5059]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0669, 0.9331],\n",
            "        [0.1231, 0.8769]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2882, 0.7118],\n",
            "        [0.0877, 0.9123]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1003, 0.8997],\n",
            "        [0.0355, 0.9645]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1100, 0.8900],\n",
            "        [0.0601, 0.9399]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0615, 0.9385],\n",
            "        [0.1458, 0.8542]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1844, 0.8156],\n",
            "        [0.1168, 0.8832]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0973, 0.9027],\n",
            "        [0.4539, 0.5461]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3916, 0.6084],\n",
            "        [0.1449, 0.8551]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0136, 0.9864],\n",
            "        [0.0397, 0.9603]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6697, 0.3303],\n",
            "        [0.2316, 0.7684]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6111, 0.3889],\n",
            "        [0.1428, 0.8572]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3656, 0.6344],\n",
            "        [0.0224, 0.9776]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0215, 0.9785],\n",
            "        [0.2947, 0.7053]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1411, 0.8589],\n",
            "        [0.3366, 0.6634]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0273, 0.9727],\n",
            "        [0.4151, 0.5849]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1266, 0.8734],\n",
            "        [0.1166, 0.8834]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0884, 0.9116],\n",
            "        [0.2468, 0.7532]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0371, 0.9629],\n",
            "        [0.0626, 0.9374]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0344, 0.9656],\n",
            "        [0.0290, 0.9710]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0730, 0.9270],\n",
            "        [0.0278, 0.9722]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5498, 0.4502],\n",
            "        [0.0072, 0.9928]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4198, 0.5802],\n",
            "        [0.0341, 0.9659]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2028, 0.7972],\n",
            "        [0.0604, 0.9396]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1587, 0.8413],\n",
            "        [0.0359, 0.9641]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0508, 0.9492],\n",
            "        [0.1327, 0.8673]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1612, 0.8388],\n",
            "        [0.0520, 0.9480]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2386, 0.7614],\n",
            "        [0.0320, 0.9680]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1472, 0.8528],\n",
            "        [0.2538, 0.7462]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2344, 0.7656],\n",
            "        [0.1195, 0.8805]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0688, 0.9312],\n",
            "        [0.0950, 0.9050]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0246, 0.9754],\n",
            "        [0.0579, 0.9421]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0383, 0.9617]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1423, 0.8577],\n",
            "        [0.0218, 0.9782]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3391, 0.6609],\n",
            "        [0.1302, 0.8698]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0217, 0.9783],\n",
            "        [0.0933, 0.9067]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0570, 0.9430],\n",
            "        [0.2097, 0.7903]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1503, 0.8497],\n",
            "        [0.0137, 0.9863]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0679, 0.9321],\n",
            "        [0.0242, 0.9758]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1450, 0.8550],\n",
            "        [0.1277, 0.8723]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0893, 0.9107],\n",
            "        [0.0807, 0.9193]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1969, 0.8031],\n",
            "        [0.1009, 0.8991]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1966, 0.8034],\n",
            "        [0.1842, 0.8158]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0313, 0.9687],\n",
            "        [0.2995, 0.7005]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2278, 0.7722],\n",
            "        [0.0604, 0.9396]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1539, 0.8461],\n",
            "        [0.1336, 0.8664]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0873, 0.9127],\n",
            "        [0.0510, 0.9490]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0379, 0.9621],\n",
            "        [0.5421, 0.4579]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0549, 0.9451],\n",
            "        [0.5076, 0.4924]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1256, 0.8744],\n",
            "        [0.0457, 0.9543]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0069, 0.9931],\n",
            "        [0.0408, 0.9592]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0227, 0.9773],\n",
            "        [0.6209, 0.3791]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2290, 0.7710],\n",
            "        [0.0236, 0.9764]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1128, 0.8872],\n",
            "        [0.6830, 0.3170]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0339, 0.9661],\n",
            "        [0.0681, 0.9319]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1481, 0.8519],\n",
            "        [0.0714, 0.9286]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0617, 0.9383],\n",
            "        [0.4042, 0.5958]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4206, 0.5794],\n",
            "        [0.2371, 0.7629]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1795, 0.8205],\n",
            "        [0.1047, 0.8953]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4633, 0.5367],\n",
            "        [0.4142, 0.5858]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1171, 0.8829],\n",
            "        [0.1393, 0.8607]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0609, 0.9391],\n",
            "        [0.0355, 0.9645]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3486, 0.6514],\n",
            "        [0.0288, 0.9712]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0995, 0.9005],\n",
            "        [0.0270, 0.9730]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1459, 0.8541],\n",
            "        [0.1568, 0.8432]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0491, 0.9509],\n",
            "        [0.1448, 0.8552]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0267, 0.9733],\n",
            "        [0.0623, 0.9377]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0328, 0.9672],\n",
            "        [0.0338, 0.9662]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1185, 0.8815],\n",
            "        [0.2530, 0.7470]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0820, 0.9180],\n",
            "        [0.0610, 0.9390]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0360, 0.9640],\n",
            "        [0.2338, 0.7662]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3754, 0.6246],\n",
            "        [0.1096, 0.8904]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1238, 0.8762],\n",
            "        [0.2955, 0.7045]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0585, 0.9415],\n",
            "        [0.1158, 0.8842]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2460, 0.7540]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0440, 0.9560],\n",
            "        [0.1463, 0.8537]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0065, 0.9935],\n",
            "        [0.0656, 0.9344]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2990, 0.7010],\n",
            "        [0.1228, 0.8772]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2243, 0.7757],\n",
            "        [0.3978, 0.6022]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1533, 0.8467],\n",
            "        [0.2436, 0.7564]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1946, 0.8054],\n",
            "        [0.0895, 0.9105]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0223, 0.9777],\n",
            "        [0.0976, 0.9024]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0320, 0.9680],\n",
            "        [0.1343, 0.8657]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5016, 0.4984],\n",
            "        [0.0129, 0.9871]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0643, 0.9357],\n",
            "        [0.0944, 0.9056]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0776, 0.9224],\n",
            "        [0.1209, 0.8791]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0519, 0.9481],\n",
            "        [0.0587, 0.9413]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2290, 0.7710],\n",
            "        [0.5313, 0.4687]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1277, 0.8723],\n",
            "        [0.0251, 0.9749]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0670, 0.9330],\n",
            "        [0.0356, 0.9644]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0558, 0.9442],\n",
            "        [0.1208, 0.8792]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0538, 0.9462],\n",
            "        [0.0375, 0.9625]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0199, 0.9801],\n",
            "        [0.6102, 0.3898]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1124, 0.8876],\n",
            "        [0.1416, 0.8584]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0843, 0.9157],\n",
            "        [0.0971, 0.9029]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4474, 0.5526],\n",
            "        [0.1256, 0.8744]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1143, 0.8857],\n",
            "        [0.1395, 0.8605]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0784, 0.9216],\n",
            "        [0.1391, 0.8609]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1089, 0.8911],\n",
            "        [0.3689, 0.6311]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1359, 0.8641],\n",
            "        [0.3347, 0.6653]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4046, 0.5954],\n",
            "        [0.1107, 0.8893]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0203, 0.9797],\n",
            "        [0.1071, 0.8929]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0229, 0.9771],\n",
            "        [0.2510, 0.7490]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1807, 0.8193],\n",
            "        [0.1012, 0.8988]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0351, 0.9649],\n",
            "        [0.0603, 0.9397]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0575, 0.9425],\n",
            "        [0.3426, 0.6574]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0322, 0.9678],\n",
            "        [0.1078, 0.8922]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1749, 0.8251],\n",
            "        [0.0340, 0.9660]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2323, 0.7677],\n",
            "        [0.0271, 0.9729]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0318, 0.9682],\n",
            "        [0.1527, 0.8473]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0298, 0.9702],\n",
            "        [0.1912, 0.8088]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0848, 0.9152],\n",
            "        [0.4157, 0.5843]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0472, 0.9528],\n",
            "        [0.2902, 0.7098]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0572, 0.9428],\n",
            "        [0.0594, 0.9406]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6800, 0.3200],\n",
            "        [0.0298, 0.9702]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2209, 0.7791],\n",
            "        [0.0258, 0.9742]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0485, 0.9515]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1096, 0.8904],\n",
            "        [0.0311, 0.9689]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0888, 0.9112],\n",
            "        [0.0339, 0.9661]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0547, 0.9453],\n",
            "        [0.1414, 0.8586]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0914, 0.9086],\n",
            "        [0.0971, 0.9029]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1527, 0.8473],\n",
            "        [0.3972, 0.6028]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0469, 0.9531],\n",
            "        [0.2257, 0.7743]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0867, 0.9133],\n",
            "        [0.1962, 0.8038]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0222, 0.9778],\n",
            "        [0.1809, 0.8191]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3020, 0.6980],\n",
            "        [0.6801, 0.3199]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0359, 0.9641],\n",
            "        [0.1088, 0.8912]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0637, 0.9363],\n",
            "        [0.0586, 0.9414]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0521, 0.9479],\n",
            "        [0.1788, 0.8212]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0598, 0.9402],\n",
            "        [0.0598, 0.9402]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1391, 0.8609],\n",
            "        [0.0311, 0.9689]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0247, 0.9753],\n",
            "        [0.0477, 0.9523]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0376, 0.9624],\n",
            "        [0.1623, 0.8377]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1437, 0.8563],\n",
            "        [0.6196, 0.3804]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4534, 0.5466],\n",
            "        [0.4025, 0.5975]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0896, 0.9104],\n",
            "        [0.0199, 0.9801]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1933, 0.8067],\n",
            "        [0.0314, 0.9686]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0662, 0.9338],\n",
            "        [0.0840, 0.9160]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1516, 0.8484],\n",
            "        [0.0202, 0.9798]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2524, 0.7476],\n",
            "        [0.0564, 0.9436]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1002, 0.8998],\n",
            "        [0.0087, 0.9913]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2235, 0.7765],\n",
            "        [0.1092, 0.8908]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0883, 0.9117],\n",
            "        [0.0800, 0.9200]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1335, 0.8665],\n",
            "        [0.0840, 0.9160]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0268, 0.9732],\n",
            "        [0.3809, 0.6191]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0576, 0.9424],\n",
            "        [0.5139, 0.4861]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1071, 0.8929],\n",
            "        [0.0252, 0.9748]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1379, 0.8621],\n",
            "        [0.4274, 0.5726]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0499, 0.9501],\n",
            "        [0.2704, 0.7296]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0296, 0.9704],\n",
            "        [0.1006, 0.8994]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1874, 0.8126],\n",
            "        [0.0323, 0.9677]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0129, 0.9871],\n",
            "        [0.1808, 0.8192]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0577, 0.9423],\n",
            "        [0.3004, 0.6996]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0598, 0.9402],\n",
            "        [0.0301, 0.9699]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4575, 0.5425],\n",
            "        [0.2002, 0.7998]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1150, 0.8850],\n",
            "        [0.1718, 0.8282]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0948, 0.9052],\n",
            "        [0.1115, 0.8885]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2330, 0.7670],\n",
            "        [0.1198, 0.8802]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3332, 0.6668]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0217, 0.9783],\n",
            "        [0.0581, 0.9419]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0595, 0.9405],\n",
            "        [0.1813, 0.8187]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0607, 0.9393],\n",
            "        [0.1006, 0.8994]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3078, 0.6922],\n",
            "        [0.2322, 0.7678]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0474, 0.9526],\n",
            "        [0.0368, 0.9632]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5220, 0.4780],\n",
            "        [0.0333, 0.9667]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0503, 0.9497],\n",
            "        [0.0582, 0.9418]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4574, 0.5426],\n",
            "        [0.1676, 0.8324]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6390, 0.3610],\n",
            "        [0.1008, 0.8992]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0380, 0.9620],\n",
            "        [0.0307, 0.9693]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1122, 0.8878],\n",
            "        [0.0545, 0.9455]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1340, 0.8660],\n",
            "        [0.1390, 0.8610]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0809, 0.9191],\n",
            "        [0.1465, 0.8535]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4691, 0.5309],\n",
            "        [0.4369, 0.5631]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0879, 0.9121],\n",
            "        [0.0322, 0.9678]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1151, 0.8849],\n",
            "        [0.1851, 0.8149]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0659, 0.9341],\n",
            "        [0.1222, 0.8778]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0642, 0.9358],\n",
            "        [0.1558, 0.8442]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2037, 0.7963],\n",
            "        [0.0910, 0.9090]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3374, 0.6626],\n",
            "        [0.0854, 0.9146]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1149, 0.8851],\n",
            "        [0.0249, 0.9751]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1102, 0.8898],\n",
            "        [0.0550, 0.9450]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2582, 0.7418],\n",
            "        [0.0248, 0.9752]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0920, 0.9080],\n",
            "        [0.0129, 0.9871]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4214, 0.5786],\n",
            "        [0.1835, 0.8165]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0204, 0.9796],\n",
            "        [0.1550, 0.8450]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0300, 0.9700],\n",
            "        [0.0998, 0.9002]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1077, 0.8923],\n",
            "        [0.2061, 0.7939]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0607, 0.9393],\n",
            "        [0.3053, 0.6947]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0478, 0.9522],\n",
            "        [0.1891, 0.8109]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0582, 0.9418],\n",
            "        [0.0859, 0.9141]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2702, 0.7298],\n",
            "        [0.6974, 0.3026]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4093, 0.5907],\n",
            "        [0.0874, 0.9126]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0287, 0.9713],\n",
            "        [0.2243, 0.7757]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2301, 0.7699],\n",
            "        [0.0902, 0.9098]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1987, 0.8013],\n",
            "        [0.0312, 0.9688]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0591, 0.9409],\n",
            "        [0.1375, 0.8625]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1462, 0.8538],\n",
            "        [0.1112, 0.8888]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0264, 0.9736],\n",
            "        [0.0905, 0.9095]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3867, 0.6133],\n",
            "        [0.1678, 0.8322]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0082, 0.9918],\n",
            "        [0.0198, 0.9802]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0292, 0.9708]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0307, 0.9693],\n",
            "        [0.0123, 0.9877]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1843, 0.8157],\n",
            "        [0.4516, 0.5484]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6385, 0.3615],\n",
            "        [0.1989, 0.8011]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0893, 0.9107],\n",
            "        [0.0578, 0.9422]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0590, 0.9410],\n",
            "        [0.0900, 0.9100]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0876, 0.9124],\n",
            "        [0.0532, 0.9468]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3054, 0.6946],\n",
            "        [0.1617, 0.8383]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2541, 0.7459],\n",
            "        [0.0081, 0.9919]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0198, 0.9802],\n",
            "        [0.0526, 0.9474]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0618, 0.9382],\n",
            "        [0.1435, 0.8565]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2264, 0.7736],\n",
            "        [0.0572, 0.9428]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1302, 0.8698],\n",
            "        [0.1093, 0.8907]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2955, 0.7045],\n",
            "        [0.0493, 0.9507]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6940, 0.3060],\n",
            "        [0.0237, 0.9763]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0206, 0.9794],\n",
            "        [0.1169, 0.8831]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0563, 0.9437],\n",
            "        [0.0456, 0.9544]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0355, 0.9645],\n",
            "        [0.0951, 0.9049]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2195, 0.7805],\n",
            "        [0.4586, 0.5414]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0557, 0.9443],\n",
            "        [0.0963, 0.9037]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1812, 0.8188],\n",
            "        [0.1665, 0.8335]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0581, 0.9419],\n",
            "        [0.0189, 0.9811]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0280, 0.9720],\n",
            "        [0.1109, 0.8891]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0833, 0.9167],\n",
            "        [0.0311, 0.9689]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0848, 0.9152],\n",
            "        [0.1459, 0.8541]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1784, 0.8216],\n",
            "        [0.3322, 0.6678]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0463, 0.9537],\n",
            "        [0.1048, 0.8952]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0583, 0.9417],\n",
            "        [0.4372, 0.5628]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2644, 0.7356],\n",
            "        [0.1525, 0.8475]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1497, 0.8503],\n",
            "        [0.1129, 0.8871]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0264, 0.9736],\n",
            "        [0.4127, 0.5873]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0309, 0.9691],\n",
            "        [0.0894, 0.9106]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2306, 0.7694],\n",
            "        [0.1045, 0.8955]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1107, 0.8893],\n",
            "        [0.0779, 0.9221]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1357, 0.8643],\n",
            "        [0.0288, 0.9712]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4069, 0.5931],\n",
            "        [0.0362, 0.9638]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0295, 0.9705],\n",
            "        [0.1993, 0.8007]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0635, 0.9365],\n",
            "        [0.0233, 0.9767]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0286, 0.9714],\n",
            "        [0.1986, 0.8014]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3924, 0.6076],\n",
            "        [0.5244, 0.4756]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0953, 0.9047],\n",
            "        [0.1819, 0.8181]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0827, 0.9173],\n",
            "        [0.0838, 0.9162]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1375, 0.8625]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0897, 0.9103],\n",
            "        [0.2347, 0.7653]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0568, 0.9432],\n",
            "        [0.0639, 0.9361]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0847, 0.9153],\n",
            "        [0.2274, 0.7726]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0363, 0.9637],\n",
            "        [0.1640, 0.8360]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0369, 0.9631],\n",
            "        [0.0979, 0.9021]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1004, 0.8996],\n",
            "        [0.0591, 0.9409]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1534, 0.8466],\n",
            "        [0.2038, 0.7962]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1152, 0.8848],\n",
            "        [0.4589, 0.5411]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0578, 0.9422],\n",
            "        [0.1107, 0.8893]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0495, 0.9505],\n",
            "        [0.1021, 0.8979]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0591, 0.9409],\n",
            "        [0.5304, 0.4696]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1461, 0.8539],\n",
            "        [0.1343, 0.8657]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0278, 0.9722],\n",
            "        [0.1171, 0.8829]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0592, 0.9408],\n",
            "        [0.1974, 0.8026]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2241, 0.7759],\n",
            "        [0.0558, 0.9442]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0187, 0.9813],\n",
            "        [0.0527, 0.9473]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2633, 0.7367],\n",
            "        [0.0077, 0.9923]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0811, 0.9189],\n",
            "        [0.1284, 0.8716]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3284, 0.6716],\n",
            "        [0.3032, 0.6968]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1019, 0.8981],\n",
            "        [0.0298, 0.9702]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1116, 0.8884],\n",
            "        [0.1469, 0.8531]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1803, 0.8197],\n",
            "        [0.4575, 0.5425]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1448, 0.8552],\n",
            "        [0.0272, 0.9728]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0882, 0.9118],\n",
            "        [0.0449, 0.9551]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1812, 0.8188],\n",
            "        [0.2519, 0.7481]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0284, 0.9716],\n",
            "        [0.0296, 0.9704]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0118, 0.9882],\n",
            "        [0.0440, 0.9560]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1683, 0.8317],\n",
            "        [0.1834, 0.8166]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0771, 0.9229],\n",
            "        [0.2039, 0.7961]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0843, 0.9157],\n",
            "        [0.4057, 0.5943]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4476, 0.5524],\n",
            "        [0.0282, 0.9718]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0583, 0.9417],\n",
            "        [0.0264, 0.9736]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1138, 0.8862],\n",
            "        [0.4047, 0.5953]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1788, 0.8212],\n",
            "        [0.0617, 0.9383]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0318, 0.9682],\n",
            "        [0.0967, 0.9033]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0198, 0.9802],\n",
            "        [0.0230, 0.9770]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0538, 0.9462],\n",
            "        [0.0832, 0.9168]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6608, 0.3392],\n",
            "        [0.0203, 0.9797]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4342, 0.5658],\n",
            "        [0.1364, 0.8636]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7129, 0.2871],\n",
            "        [0.0895, 0.9105]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3154, 0.6846],\n",
            "        [0.0926, 0.9074]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0237, 0.9763]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0311, 0.9689],\n",
            "        [0.2600, 0.7400]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0861, 0.9139],\n",
            "        [0.2013, 0.7987]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4612, 0.5388],\n",
            "        [0.3346, 0.6654]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0854, 0.9146],\n",
            "        [0.0995, 0.9005]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3151, 0.6849],\n",
            "        [0.0196, 0.9804]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0599, 0.9401],\n",
            "        [0.1667, 0.8333]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5460, 0.4540],\n",
            "        [0.0834, 0.9166]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7166, 0.2834],\n",
            "        [0.1788, 0.8212]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0271, 0.9729],\n",
            "        [0.0195, 0.9805]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4682, 0.5318],\n",
            "        [0.0323, 0.9677]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0378, 0.9622],\n",
            "        [0.0307, 0.9693]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0271, 0.9729],\n",
            "        [0.4198, 0.5802]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1142, 0.8858],\n",
            "        [0.0595, 0.9405]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1924, 0.8076],\n",
            "        [0.0621, 0.9379]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0442, 0.9558],\n",
            "        [0.1545, 0.8455]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0827, 0.9173],\n",
            "        [0.0626, 0.9374]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0503, 0.9497],\n",
            "        [0.1523, 0.8477]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0917, 0.9083],\n",
            "        [0.1336, 0.8664]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0606, 0.9394],\n",
            "        [0.2766, 0.7234]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1740, 0.8260],\n",
            "        [0.0588, 0.9412]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4108, 0.5892],\n",
            "        [0.0892, 0.9108]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0231, 0.9769],\n",
            "        [0.1907, 0.8093]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1067, 0.8933],\n",
            "        [0.0959, 0.9041]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0776, 0.9224],\n",
            "        [0.1185, 0.8815]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1537, 0.8463],\n",
            "        [0.0619, 0.9381]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0569, 0.9431],\n",
            "        [0.2152, 0.7848]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1201, 0.8799],\n",
            "        [0.2072, 0.7928]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0462, 0.9538],\n",
            "        [0.0076, 0.9924]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0196, 0.9804],\n",
            "        [0.0983, 0.9017]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4727, 0.5273],\n",
            "        [0.0345, 0.9655]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0532, 0.9468],\n",
            "        [0.1885, 0.8115]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0912, 0.9088],\n",
            "        [0.1177, 0.8823]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0280, 0.9720],\n",
            "        [0.0221, 0.9779]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0906, 0.9094],\n",
            "        [0.4309, 0.5691]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0549, 0.9451],\n",
            "        [0.1335, 0.8665]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1125, 0.8875],\n",
            "        [0.0273, 0.9727]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0564, 0.9436],\n",
            "        [0.2313, 0.7687]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6593, 0.3407],\n",
            "        [0.0994, 0.9006]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1281, 0.8719],\n",
            "        [0.1497, 0.8503]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3043, 0.6957],\n",
            "        [0.0274, 0.9726]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0117, 0.9883],\n",
            "        [0.2370, 0.7630]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2238, 0.7762]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1112, 0.8888],\n",
            "        [0.0485, 0.9515]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1510, 0.8490],\n",
            "        [0.0291, 0.9709]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0571, 0.9429],\n",
            "        [0.1869, 0.8131]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1120, 0.8880],\n",
            "        [0.0369, 0.9631]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0184, 0.9816],\n",
            "        [0.7171, 0.2829]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2695, 0.7305],\n",
            "        [0.2158, 0.7842]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0075, 0.9925],\n",
            "        [0.0906, 0.9094]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0935, 0.9065],\n",
            "        [0.0999, 0.9001]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1188, 0.8812],\n",
            "        [0.0591, 0.9409]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1296, 0.8704],\n",
            "        [0.0183, 0.9817]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0818, 0.9182],\n",
            "        [0.0260, 0.9740]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1032, 0.8968],\n",
            "        [0.0603, 0.9397]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0875, 0.9125],\n",
            "        [0.4371, 0.5629]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1482, 0.8518],\n",
            "        [0.0254, 0.9746]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5498, 0.4502],\n",
            "        [0.0305, 0.9695]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0523, 0.9477],\n",
            "        [0.0769, 0.9231]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0116, 0.9884],\n",
            "        [0.2330, 0.7670]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1768, 0.8232],\n",
            "        [0.0880, 0.9120]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4214, 0.5786],\n",
            "        [0.0331, 0.9669]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1881, 0.8119],\n",
            "        [0.0411, 0.9589]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4665, 0.5335],\n",
            "        [0.1528, 0.8472]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0274, 0.9726],\n",
            "        [0.0981, 0.9019]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2386, 0.7614],\n",
            "        [0.4772, 0.5228]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3134, 0.6866],\n",
            "        [0.6688, 0.3312]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0572, 0.9428],\n",
            "        [0.1166, 0.8834]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2098, 0.7902],\n",
            "        [0.0554, 0.9446]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1932, 0.8068],\n",
            "        [0.0577, 0.9423]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1351, 0.8649],\n",
            "        [0.0289, 0.9711]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4077, 0.5923],\n",
            "        [0.0854, 0.9146]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4668, 0.5332],\n",
            "        [0.0218, 0.9782]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3272, 0.6728],\n",
            "        [0.0911, 0.9089]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0210, 0.9790],\n",
            "        [0.1228, 0.8772]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0275, 0.9725],\n",
            "        [0.3093, 0.6907]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1632, 0.8368],\n",
            "        [0.2197, 0.7803]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0956, 0.9044],\n",
            "        [0.0604, 0.9396]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2574, 0.7426],\n",
            "        [0.0196, 0.9804]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1555, 0.8445],\n",
            "        [0.0267, 0.9733]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1321, 0.8679],\n",
            "        [0.2024, 0.7976]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0796, 0.9204],\n",
            "        [0.0827, 0.9173]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0455, 0.9545],\n",
            "        [0.0593, 0.9407]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0600, 0.9400],\n",
            "        [0.1730, 0.8270]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0567, 0.9433]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0290, 0.9710],\n",
            "        [0.4313, 0.5687]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0842, 0.9158],\n",
            "        [0.1617, 0.8383]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1275, 0.8725],\n",
            "        [0.0558, 0.9442]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1543, 0.8457],\n",
            "        [0.2590, 0.7410]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0591, 0.9409],\n",
            "        [0.0272, 0.9728]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1165, 0.8835],\n",
            "        [0.1555, 0.8445]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3106, 0.6894],\n",
            "        [0.0920, 0.9080]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1319, 0.8681],\n",
            "        [0.0597, 0.9403]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4070, 0.5930],\n",
            "        [0.1212, 0.8788]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0610, 0.9390],\n",
            "        [0.0832, 0.9168]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1135, 0.8865],\n",
            "        [0.1584, 0.8416]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0198, 0.9802],\n",
            "        [0.0576, 0.9424]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0248, 0.9752],\n",
            "        [0.1343, 0.8657]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5598, 0.4402],\n",
            "        [0.0893, 0.9107]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1242, 0.8758],\n",
            "        [0.1009, 0.8991]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0374, 0.9626],\n",
            "        [0.0584, 0.9416]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1767, 0.8233],\n",
            "        [0.0998, 0.9002]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6780, 0.3220],\n",
            "        [0.4442, 0.5558]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0217, 0.9783],\n",
            "        [0.2122, 0.7878]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0115, 0.9885],\n",
            "        [0.1479, 0.8521]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4777, 0.5223],\n",
            "        [0.2029, 0.7971]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0942, 0.9058],\n",
            "        [0.7250, 0.2750]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4627, 0.5373],\n",
            "        [0.1895, 0.8105]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0751, 0.9249],\n",
            "        [0.0517, 0.9483]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3147, 0.6853],\n",
            "        [0.0487, 0.9513]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1106, 0.8894],\n",
            "        [0.2681, 0.7319]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0590, 0.9410],\n",
            "        [0.2177, 0.7823]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0767, 0.9233],\n",
            "        [0.2183, 0.7817]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0872, 0.9128],\n",
            "        [0.3190, 0.6810]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0396, 0.9604],\n",
            "        [0.2285, 0.7715]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0259, 0.9741],\n",
            "        [0.1683, 0.8317]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0169, 0.9831],\n",
            "        [0.0069, 0.9931]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0559, 0.9441],\n",
            "        [0.4710, 0.5290]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0202, 0.9798],\n",
            "        [0.0261, 0.9739]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0249, 0.9751],\n",
            "        [0.1852, 0.8148]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2353, 0.7647],\n",
            "        [0.0292, 0.9708]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0568, 0.9432],\n",
            "        [0.1929, 0.8071]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0879, 0.9121],\n",
            "        [0.0850, 0.9150]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0555, 0.9445],\n",
            "        [0.0276, 0.9724]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0986, 0.9014],\n",
            "        [0.0316, 0.9684]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0174, 0.9826],\n",
            "        [0.0445, 0.9555]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0799, 0.9201]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0976, 0.9024],\n",
            "        [0.1145, 0.8855]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1749, 0.8251],\n",
            "        [0.2015, 0.7985]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0574, 0.9426],\n",
            "        [0.0803, 0.9197]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0111, 0.9889],\n",
            "        [0.1528, 0.8472]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0297, 0.9703],\n",
            "        [0.1557, 0.8443]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0548, 0.9452],\n",
            "        [0.2215, 0.7785]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0168, 0.9832],\n",
            "        [0.0977, 0.9023]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1312, 0.8688],\n",
            "        [0.2172, 0.7828]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0252, 0.9748],\n",
            "        [0.0279, 0.9721]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0772, 0.9228],\n",
            "        [0.1237, 0.8763]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1104, 0.8896],\n",
            "        [0.4017, 0.5983]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0852, 0.9148],\n",
            "        [0.2095, 0.7905]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0878, 0.9122],\n",
            "        [0.3158, 0.6842]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0782, 0.9218],\n",
            "        [0.0259, 0.9741]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1693, 0.8307],\n",
            "        [0.0503, 0.9497]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1554, 0.8446],\n",
            "        [0.0550, 0.9450]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0538, 0.9462],\n",
            "        [0.4748, 0.5252]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0559, 0.9441],\n",
            "        [0.0574, 0.9426]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0856, 0.9144],\n",
            "        [0.1924, 0.8076]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4302, 0.5698],\n",
            "        [0.0556, 0.9444]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0256, 0.9744],\n",
            "        [0.3166, 0.6834]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0253, 0.9747],\n",
            "        [0.1203, 0.8797]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2641, 0.7359],\n",
            "        [0.0183, 0.9817]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1193, 0.8807],\n",
            "        [0.3019, 0.6981]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0268, 0.9732],\n",
            "        [0.0813, 0.9187]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2544, 0.7456],\n",
            "        [0.0873, 0.9127]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0546, 0.9454],\n",
            "        [0.0171, 0.9829]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2408, 0.7592],\n",
            "        [0.4416, 0.5584]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2347, 0.7653],\n",
            "        [0.0204, 0.9796]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0901, 0.9099],\n",
            "        [0.4795, 0.5205]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7306, 0.2694],\n",
            "        [0.0386, 0.9614]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1301, 0.8699],\n",
            "        [0.4642, 0.5358]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1890, 0.8110],\n",
            "        [0.0314, 0.9686]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0482, 0.9518],\n",
            "        [0.0881, 0.9119]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6834, 0.3166],\n",
            "        [0.1460, 0.8540]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0199, 0.9801],\n",
            "        [0.1906, 0.8094]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1121, 0.8879],\n",
            "        [0.0747, 0.9253]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0068, 0.9932],\n",
            "        [0.0997, 0.9003]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0231, 0.9769],\n",
            "        [0.0565, 0.9435]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0372, 0.9628],\n",
            "        [0.1535, 0.8465]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0606, 0.9394],\n",
            "        [0.5650, 0.4350]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0447, 0.9553]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1560, 0.8440],\n",
            "        [0.2372, 0.7628]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0278, 0.9722],\n",
            "        [0.0205, 0.9795]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0191, 0.9809],\n",
            "        [0.0514, 0.9486]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0254, 0.9746],\n",
            "        [0.0164, 0.9836]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1230, 0.8770],\n",
            "        [0.0569, 0.9431]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2607, 0.7393],\n",
            "        [0.0776, 0.9224]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4883, 0.5117],\n",
            "        [0.1115, 0.8885]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6899, 0.3101],\n",
            "        [0.0809, 0.9191]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0825, 0.9175],\n",
            "        [0.2169, 0.7831]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0572, 0.9428],\n",
            "        [0.2180, 0.7820]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1012, 0.8988],\n",
            "        [0.0178, 0.9822]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0259, 0.9741],\n",
            "        [0.1326, 0.8674]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0231, 0.9769],\n",
            "        [0.3300, 0.6700]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0268, 0.9732],\n",
            "        [0.0920, 0.9080]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0321, 0.9679],\n",
            "        [0.0113, 0.9887]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1478, 0.8522],\n",
            "        [0.0811, 0.9189]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0375, 0.9625],\n",
            "        [0.1759, 0.8241]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0261, 0.9739],\n",
            "        [0.7399, 0.2601]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4600, 0.5400],\n",
            "        [0.1135, 0.8865]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0564, 0.9436],\n",
            "        [0.3150, 0.6850]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0575, 0.9425],\n",
            "        [0.0873, 0.9127]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2063, 0.7937],\n",
            "        [0.0305, 0.9695]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0925, 0.9075],\n",
            "        [0.1765, 0.8235]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4714, 0.5286],\n",
            "        [0.2025, 0.7975]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0761, 0.9239],\n",
            "        [0.1267, 0.8733]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0196, 0.9804],\n",
            "        [0.1243, 0.8757]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0067, 0.9933],\n",
            "        [0.1897, 0.8103]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0486, 0.9514],\n",
            "        [0.0603, 0.9397]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1916, 0.8084],\n",
            "        [0.4467, 0.5533]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1152, 0.8848],\n",
            "        [0.0562, 0.9438]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0975, 0.9025],\n",
            "        [0.2273, 0.7727]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2449, 0.7551],\n",
            "        [0.0556, 0.9444]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4027, 0.5973],\n",
            "        [0.0574, 0.9426]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4943, 0.5057],\n",
            "        [0.0994, 0.9006]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0444, 0.9556],\n",
            "        [0.1538, 0.8462]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0588, 0.9412],\n",
            "        [0.0870, 0.9130]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0869, 0.9131],\n",
            "        [0.1609, 0.8391]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5704, 0.4296],\n",
            "        [0.1318, 0.8682]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0873, 0.9127],\n",
            "        [0.0382, 0.9618]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1589, 0.8411],\n",
            "        [0.2713, 0.7287]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3184, 0.6816],\n",
            "        [0.0564, 0.9436]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0267, 0.9733]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0380, 0.9620],\n",
            "        [0.0560, 0.9440]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4986, 0.5014],\n",
            "        [0.3249, 0.6751]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2614, 0.7386],\n",
            "        [0.2052, 0.7948]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3192, 0.6808],\n",
            "        [0.0591, 0.9409]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0558, 0.9442],\n",
            "        [0.0372, 0.9628]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1746, 0.8254],\n",
            "        [0.0858, 0.9142]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0996, 0.9004],\n",
            "        [0.0563, 0.9437]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0488, 0.9512],\n",
            "        [0.1921, 0.8079]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1922, 0.8078],\n",
            "        [0.0201, 0.9799]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1001, 0.8999],\n",
            "        [0.0905, 0.9095]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1600, 0.8400],\n",
            "        [0.2172, 0.7828]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0876, 0.9124],\n",
            "        [0.0563, 0.9437]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5754, 0.4246],\n",
            "        [0.0312, 0.9688]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0262, 0.9738],\n",
            "        [0.0158, 0.9842]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4047, 0.5953],\n",
            "        [0.0109, 0.9891]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0189, 0.9811],\n",
            "        [0.1246, 0.8754]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4588, 0.5412],\n",
            "        [0.1155, 0.8845]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0865, 0.9135],\n",
            "        [0.0065, 0.9935]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0444, 0.9556],\n",
            "        [0.1532, 0.8468]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0572, 0.9428],\n",
            "        [0.0737, 0.9263]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1430, 0.8570],\n",
            "        [0.1555, 0.8445]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2016, 0.7984],\n",
            "        [0.4652, 0.5348]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0756, 0.9244],\n",
            "        [0.0550, 0.9450]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0245, 0.9755],\n",
            "        [0.1292, 0.8708]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4496, 0.5504],\n",
            "        [0.0188, 0.9812]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0775, 0.9225],\n",
            "        [0.1732, 0.8268]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0881, 0.9119],\n",
            "        [0.0165, 0.9835]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0940, 0.9060],\n",
            "        [0.0599, 0.9401]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0545, 0.9455],\n",
            "        [0.0286, 0.9714]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2638, 0.7362],\n",
            "        [0.1278, 0.8722]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3063, 0.6937],\n",
            "        [0.2397, 0.7603]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1239, 0.8761],\n",
            "        [0.0256, 0.9744]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1176, 0.8824],\n",
            "        [0.0547, 0.9453]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0246, 0.9754],\n",
            "        [0.2130, 0.7870]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2321, 0.7679],\n",
            "        [0.0784, 0.9216]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2255, 0.7745],\n",
            "        [0.4784, 0.5216]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1089, 0.8911],\n",
            "        [0.0214, 0.9786]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0258, 0.9742],\n",
            "        [0.0838, 0.9162]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0778, 0.9222],\n",
            "        [0.0492, 0.9508]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6917, 0.3083],\n",
            "        [0.0244, 0.9756]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1593, 0.8407],\n",
            "        [0.1090, 0.8910]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7392, 0.2608]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2606, 0.7394],\n",
            "        [0.1534, 0.8466]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0497, 0.9503],\n",
            "        [0.3100, 0.6900]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0369, 0.9631],\n",
            "        [0.1134, 0.8866]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3978, 0.6022],\n",
            "        [0.0841, 0.9159]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1280, 0.8720],\n",
            "        [0.1428, 0.8572]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4900, 0.5100],\n",
            "        [0.0558, 0.9442]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6995, 0.3005],\n",
            "        [0.1307, 0.8693]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0885, 0.9115],\n",
            "        [0.4614, 0.5386]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0301, 0.9699],\n",
            "        [0.7461, 0.2539]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0609, 0.9391],\n",
            "        [0.0904, 0.9096]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0372, 0.9628],\n",
            "        [0.0978, 0.9022]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1248, 0.8752],\n",
            "        [0.0542, 0.9458]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2067, 0.7933],\n",
            "        [0.0488, 0.9512]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0796, 0.9204],\n",
            "        [0.1929, 0.8071]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0193, 0.9807],\n",
            "        [0.0248, 0.9752]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0246, 0.9754],\n",
            "        [0.4697, 0.5303]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0957, 0.9043],\n",
            "        [0.0264, 0.9736]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1106, 0.8894],\n",
            "        [0.1108, 0.8892]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1619, 0.8381],\n",
            "        [0.0734, 0.9266]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2130, 0.7870],\n",
            "        [0.0062, 0.9938]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0246, 0.9754],\n",
            "        [0.0211, 0.9789]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1514, 0.8486],\n",
            "        [0.0787, 0.9213]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0562, 0.9438],\n",
            "        [0.0765, 0.9235]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2025, 0.7975],\n",
            "        [0.0282, 0.9718]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5753, 0.4247],\n",
            "        [0.0527, 0.9473]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1174, 0.8826],\n",
            "        [0.0539, 0.9461]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0540, 0.9460],\n",
            "        [0.2622, 0.7378]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0248, 0.9752],\n",
            "        [0.1700, 0.8300]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0539, 0.9461],\n",
            "        [0.5014, 0.4986]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2324, 0.7676],\n",
            "        [0.0182, 0.9818]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4569, 0.5431],\n",
            "        [0.1272, 0.8728]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0426, 0.9574],\n",
            "        [0.3124, 0.6876]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0547, 0.9453],\n",
            "        [0.1723, 0.8277]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0828, 0.9172],\n",
            "        [0.0160, 0.9840]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2166, 0.7834],\n",
            "        [0.0741, 0.9259]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0567, 0.9433],\n",
            "        [0.0179, 0.9821]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0829, 0.9171],\n",
            "        [0.1875, 0.8125]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0102, 0.9898],\n",
            "        [0.3245, 0.6755]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0968, 0.9032],\n",
            "        [0.1547, 0.8453]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2312, 0.7688],\n",
            "        [0.0145, 0.9855]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0247, 0.9753],\n",
            "        [0.0839, 0.9161]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2446, 0.7554]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0289, 0.9711],\n",
            "        [0.0526, 0.9474]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2669, 0.7331],\n",
            "        [0.0370, 0.9630]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0243, 0.9757],\n",
            "        [0.5133, 0.4867]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0850, 0.9150],\n",
            "        [0.0773, 0.9227]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0851, 0.9149],\n",
            "        [0.0795, 0.9205]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0562, 0.9438],\n",
            "        [0.2072, 0.7928]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0849, 0.9151],\n",
            "        [0.0299, 0.9701]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0206, 0.9794],\n",
            "        [0.1767, 0.8233]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1326, 0.8674],\n",
            "        [0.0917, 0.9083]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0568, 0.9432],\n",
            "        [0.0247, 0.9753]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2152, 0.7848],\n",
            "        [0.1700, 0.8300]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0494, 0.9506],\n",
            "        [0.3181, 0.6819]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0191, 0.9809],\n",
            "        [0.1741, 0.8259]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0194, 0.9806],\n",
            "        [0.0452, 0.9548]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1307, 0.8693],\n",
            "        [0.7174, 0.2826]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0257, 0.9743],\n",
            "        [0.2146, 0.7854]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2676, 0.7324],\n",
            "        [0.1675, 0.8325]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5131, 0.4869],\n",
            "        [0.1995, 0.8005]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0112, 0.9888],\n",
            "        [0.6011, 0.3989]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2002, 0.7998],\n",
            "        [0.4931, 0.5069]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1377, 0.8623],\n",
            "        [0.0576, 0.9424]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0534, 0.9466],\n",
            "        [0.5008, 0.4992]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0908, 0.9092],\n",
            "        [0.1173, 0.8827]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0275, 0.9725],\n",
            "        [0.0262, 0.9738]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1082, 0.8918],\n",
            "        [0.0917, 0.9083]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4953, 0.5047],\n",
            "        [0.0812, 0.9188]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3302, 0.6698],\n",
            "        [0.4236, 0.5764]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1027, 0.8973],\n",
            "        [0.0294, 0.9706]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1263, 0.8737],\n",
            "        [0.0184, 0.9816]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0667, 0.9333],\n",
            "        [0.2603, 0.7397]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7726, 0.2274],\n",
            "        [0.0588, 0.9412]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2379, 0.7621],\n",
            "        [0.1236, 0.8764]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0379, 0.9621],\n",
            "        [0.1682, 0.8318]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0612, 0.9388],\n",
            "        [0.0622, 0.9378]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0630, 0.9370],\n",
            "        [0.2592, 0.7408]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3586, 0.6414],\n",
            "        [0.1057, 0.8943]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1450, 0.8550],\n",
            "        [0.0590, 0.9410]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0064, 0.9936],\n",
            "        [0.0798, 0.9202]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1602, 0.8398],\n",
            "        [0.2711, 0.7289]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0175, 0.9825],\n",
            "        [0.1482, 0.8518]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0148, 0.9852],\n",
            "        [0.1172, 0.8828]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0809, 0.9191]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2202, 0.7798],\n",
            "        [0.2552, 0.7448]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6044, 0.3956],\n",
            "        [0.0368, 0.9632]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1713, 0.8287],\n",
            "        [0.1992, 0.8008]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0546, 0.9454],\n",
            "        [0.1751, 0.8249]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0892, 0.9108],\n",
            "        [0.1442, 0.8558]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1199, 0.8801],\n",
            "        [0.0063, 0.9937]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0197, 0.9803],\n",
            "        [0.4927, 0.5073]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5189, 0.4811],\n",
            "        [0.4970, 0.5030]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0628, 0.9372],\n",
            "        [0.0785, 0.9215]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0579, 0.9421],\n",
            "        [0.2348, 0.7652]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0196, 0.9804],\n",
            "        [0.0884, 0.9116]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0255, 0.9745],\n",
            "        [0.0907, 0.9093]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2042, 0.7958],\n",
            "        [0.4167, 0.5833]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1153, 0.8847],\n",
            "        [0.0264, 0.9736]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1073, 0.8927],\n",
            "        [0.0174, 0.9826]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0307, 0.9693],\n",
            "        [0.1190, 0.8810]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0199, 0.9801],\n",
            "        [0.0505, 0.9495]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1478, 0.8522],\n",
            "        [0.0804, 0.9196]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2837, 0.7163],\n",
            "        [0.2586, 0.7414]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0617, 0.9383],\n",
            "        [0.0277, 0.9723]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0771, 0.9229],\n",
            "        [0.0109, 0.9891]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2718, 0.7282],\n",
            "        [0.1350, 0.8650]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0870, 0.9130],\n",
            "        [0.1344, 0.8656]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0596, 0.9404],\n",
            "        [0.0175, 0.9825]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0562, 0.9438],\n",
            "        [0.3189, 0.6811]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0141, 0.9859],\n",
            "        [0.3545, 0.6455]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2110, 0.7890],\n",
            "        [0.0241, 0.9759]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0389, 0.9611],\n",
            "        [0.0575, 0.9425]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1803, 0.8197],\n",
            "        [0.0444, 0.9556]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0968, 0.9032],\n",
            "        [0.0857, 0.9143]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0511, 0.9489],\n",
            "        [0.1041, 0.8959]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1561, 0.8439],\n",
            "        [0.7270, 0.2730]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2693, 0.7307],\n",
            "        [0.0937, 0.9063]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0578, 0.9422],\n",
            "        [0.1759, 0.8241]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7686, 0.2314],\n",
            "        [0.0241, 0.9759]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0574, 0.9426],\n",
            "        [0.0799, 0.9201]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2137, 0.7863],\n",
            "        [0.4937, 0.5063]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5370, 0.4630],\n",
            "        [0.3181, 0.6819]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1598, 0.8402],\n",
            "        [0.0781, 0.9219]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0253, 0.9747],\n",
            "        [0.0304, 0.9696]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0558, 0.9442],\n",
            "        [0.1177, 0.8823]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1340, 0.8660]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0761, 0.9239],\n",
            "        [0.0571, 0.9429]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1333, 0.8667],\n",
            "        [0.1739, 0.8261]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0852, 0.9148],\n",
            "        [0.1310, 0.8690]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7679, 0.2321],\n",
            "        [0.1156, 0.8844]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0250, 0.9750],\n",
            "        [0.1958, 0.8042]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0944, 0.9056],\n",
            "        [0.1020, 0.8980]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1390, 0.8610],\n",
            "        [0.3448, 0.6552]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0285, 0.9715],\n",
            "        [0.1423, 0.8577]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0345, 0.9655],\n",
            "        [0.0236, 0.9764]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1549, 0.8451],\n",
            "        [0.4826, 0.5174]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0159, 0.9841],\n",
            "        [0.0250, 0.9750]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2464, 0.7536],\n",
            "        [0.0578, 0.9422]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2645, 0.7355],\n",
            "        [0.1108, 0.8892]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0509, 0.9491],\n",
            "        [0.0056, 0.9944]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5950, 0.4050],\n",
            "        [0.0788, 0.9212]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2196, 0.7804],\n",
            "        [0.0180, 0.9820]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4829, 0.5171],\n",
            "        [0.1289, 0.8711]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0427, 0.9573],\n",
            "        [0.0822, 0.9178]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0741, 0.9259],\n",
            "        [0.1097, 0.8903]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0868, 0.9132],\n",
            "        [0.0233, 0.9767]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1711, 0.8289],\n",
            "        [0.0983, 0.9017]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0132, 0.9868],\n",
            "        [0.1677, 0.8323]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0755, 0.9245],\n",
            "        [0.0752, 0.9248]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0368, 0.9632],\n",
            "        [0.4927, 0.5073]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0845, 0.9155],\n",
            "        [0.2072, 0.7928]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0537, 0.9463],\n",
            "        [0.0519, 0.9481]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1502, 0.8498],\n",
            "        [0.0689, 0.9311]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2531, 0.7469],\n",
            "        [0.2118, 0.7882]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0472, 0.9528],\n",
            "        [0.5289, 0.4711]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2057, 0.7943],\n",
            "        [0.0283, 0.9717]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7200, 0.2800],\n",
            "        [0.0174, 0.9826]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1575, 0.8425],\n",
            "        [0.0524, 0.9476]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0576, 0.9424],\n",
            "        [0.2716, 0.7284]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0242, 0.9758],\n",
            "        [0.0566, 0.9434]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0496, 0.9504],\n",
            "        [0.0102, 0.9898]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2486, 0.7514],\n",
            "        [0.3143, 0.6857]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4045, 0.5955],\n",
            "        [0.0228, 0.9772]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2003, 0.7997],\n",
            "        [0.4829, 0.5171]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0563, 0.9437],\n",
            "        [0.0184, 0.9816]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0542, 0.9458],\n",
            "        [0.1132, 0.8868]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0841, 0.9159],\n",
            "        [0.0165, 0.9835]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3134, 0.6866]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1110, 0.8890],\n",
            "        [0.1302, 0.8698]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0567, 0.9433],\n",
            "        [0.0483, 0.9517]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0801, 0.9199],\n",
            "        [0.0895, 0.9105]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0291, 0.9709],\n",
            "        [0.1724, 0.8276]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2526, 0.7474],\n",
            "        [0.0553, 0.9447]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0508, 0.9492],\n",
            "        [0.0158, 0.9842]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0537, 0.9463],\n",
            "        [0.2643, 0.7357]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0586, 0.9414],\n",
            "        [0.5425, 0.4575]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1152, 0.8848],\n",
            "        [0.0382, 0.9618]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3172, 0.6828],\n",
            "        [0.0534, 0.9466]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0841, 0.9159],\n",
            "        [0.4861, 0.5139]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0759, 0.9241],\n",
            "        [0.3511, 0.6489]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2110, 0.7890],\n",
            "        [0.0766, 0.9234]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0259, 0.9741],\n",
            "        [0.4972, 0.5028]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0186, 0.9814],\n",
            "        [0.0167, 0.9833]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1019, 0.8981],\n",
            "        [0.1149, 0.8851]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1568, 0.8432],\n",
            "        [0.0775, 0.9225]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7315, 0.2685],\n",
            "        [0.0056, 0.9944]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0441, 0.9559],\n",
            "        [0.0133, 0.9867]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1993, 0.8007],\n",
            "        [0.2726, 0.7274]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1395, 0.8605],\n",
            "        [0.0845, 0.9155]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5054, 0.4946],\n",
            "        [0.4971, 0.5029]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1617, 0.8383],\n",
            "        [0.2264, 0.7736]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0772, 0.9228],\n",
            "        [0.0100, 0.9900]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0715, 0.9285],\n",
            "        [0.0245, 0.9755]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3192, 0.6808],\n",
            "        [0.1329, 0.8671]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1414, 0.8586],\n",
            "        [0.7735, 0.2265]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0541, 0.9459],\n",
            "        [0.1702, 0.8298]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0342, 0.9658],\n",
            "        [0.0853, 0.9147]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0582, 0.9418],\n",
            "        [0.1553, 0.8447]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0557, 0.9443],\n",
            "        [0.2198, 0.7802]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0174, 0.9826],\n",
            "        [0.0486, 0.9514]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0231, 0.9769],\n",
            "        [0.2076, 0.7924]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0247, 0.9753],\n",
            "        [0.0230, 0.9770]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1957, 0.8043],\n",
            "        [0.6098, 0.3902]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4078, 0.5922],\n",
            "        [0.0562, 0.9438]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2694, 0.7306],\n",
            "        [0.0825, 0.9175]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0187, 0.9813],\n",
            "        [0.1154, 0.8846]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1772, 0.8228],\n",
            "        [0.1009, 0.8991]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0230, 0.9770],\n",
            "        [0.0920, 0.9080]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1291, 0.8709],\n",
            "        [0.0281, 0.9719]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2498, 0.7502]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0917, 0.9083],\n",
            "        [0.0230, 0.9770]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0383, 0.9617],\n",
            "        [0.0230, 0.9770]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0842, 0.9158],\n",
            "        [0.0824, 0.9176]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0763, 0.9237],\n",
            "        [0.0277, 0.9723]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7355, 0.2645],\n",
            "        [0.1407, 0.8593]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1702, 0.8298],\n",
            "        [0.1406, 0.8594]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0129, 0.9871],\n",
            "        [0.0494, 0.9506]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1649, 0.8351],\n",
            "        [0.1118, 0.8882]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0337, 0.9663],\n",
            "        [0.3147, 0.6853]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0498, 0.9502],\n",
            "        [0.0227, 0.9773]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0564, 0.9436],\n",
            "        [0.0580, 0.9420]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0055, 0.9945],\n",
            "        [0.1521, 0.8479]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2235, 0.7765],\n",
            "        [0.0293, 0.9707]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1004, 0.8996],\n",
            "        [0.2071, 0.7929]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0730, 0.9270],\n",
            "        [0.4834, 0.5166]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4032, 0.5968],\n",
            "        [0.0175, 0.9825]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0557, 0.9443],\n",
            "        [0.1754, 0.8246]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1715, 0.8285],\n",
            "        [0.2712, 0.7288]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2110, 0.7890],\n",
            "        [0.2532, 0.7468]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2434, 0.7566],\n",
            "        [0.5019, 0.4981]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0584, 0.9416],\n",
            "        [0.0187, 0.9813]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0181, 0.9819],\n",
            "        [0.1957, 0.8043]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1529, 0.8471],\n",
            "        [0.3499, 0.6501]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0162, 0.9838],\n",
            "        [0.2638, 0.7362]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0531, 0.9469],\n",
            "        [0.0246, 0.9754]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0538, 0.9462],\n",
            "        [0.1959, 0.8041]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1149, 0.8851],\n",
            "        [0.6116, 0.3884]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0239, 0.9761],\n",
            "        [0.5101, 0.4899]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0157, 0.9843],\n",
            "        [0.0099, 0.9901]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4992, 0.5008],\n",
            "        [0.0769, 0.9231]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0431, 0.9569],\n",
            "        [0.0508, 0.9492]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2347, 0.7653],\n",
            "        [0.2684, 0.7316]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0741, 0.9259],\n",
            "        [0.1107, 0.8893]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1148, 0.8852],\n",
            "        [0.0471, 0.9529]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3219, 0.6781],\n",
            "        [0.0749, 0.9251]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0825, 0.9175],\n",
            "        [0.0242, 0.9758]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0785, 0.9215],\n",
            "        [0.0823, 0.9177]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5452, 0.4548],\n",
            "        [0.0563, 0.9437]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1270, 0.8730],\n",
            "        [0.7727, 0.2273]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0982, 0.9018],\n",
            "        [0.0901, 0.9099]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0538, 0.9462],\n",
            "        [0.1338, 0.8662]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1309, 0.8691]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0159, 0.9841],\n",
            "        [0.2229, 0.7771]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1307, 0.8693],\n",
            "        [0.1944, 0.8056]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1264, 0.8736],\n",
            "        [0.0778, 0.9222]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2618, 0.7382],\n",
            "        [0.0234, 0.9766]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0577, 0.9423],\n",
            "        [0.3960, 0.6040]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0175, 0.9825],\n",
            "        [0.0556, 0.9444]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0801, 0.9199],\n",
            "        [0.0152, 0.9848]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1399, 0.8601],\n",
            "        [0.0831, 0.9169]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2546, 0.7454],\n",
            "        [0.0733, 0.9267]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0263, 0.9737],\n",
            "        [0.1112, 0.8888]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2314, 0.7686],\n",
            "        [0.0539, 0.9461]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0490, 0.9510],\n",
            "        [0.0219, 0.9781]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0482, 0.9518],\n",
            "        [0.2727, 0.7273]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0759, 0.9241],\n",
            "        [0.3114, 0.6886]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0737, 0.9263],\n",
            "        [0.2453, 0.7547]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0429, 0.9571],\n",
            "        [0.1749, 0.8251]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0328, 0.9672],\n",
            "        [0.4821, 0.5179]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5105, 0.4895],\n",
            "        [0.0170, 0.9830]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2000, 0.8000],\n",
            "        [0.1369, 0.8631]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0543, 0.9457],\n",
            "        [0.0242, 0.9758]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0994, 0.9006],\n",
            "        [0.0509, 0.9491]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6165, 0.3835],\n",
            "        [0.0247, 0.9753]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2107, 0.7893],\n",
            "        [0.5007, 0.4993]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0477, 0.9523],\n",
            "        [0.2692, 0.7308]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3490, 0.6510],\n",
            "        [0.0384, 0.9616]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1386, 0.8614],\n",
            "        [0.1001, 0.8999]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1495, 0.8505],\n",
            "        [0.0526, 0.9474]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0865, 0.9135],\n",
            "        [0.0689, 0.9311]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0799, 0.9201],\n",
            "        [0.3166, 0.6834]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7731, 0.2269],\n",
            "        [0.0551, 0.9449]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1439, 0.8561],\n",
            "        [0.0096, 0.9904]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0713, 0.9287],\n",
            "        [0.1098, 0.8902]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4966, 0.5034],\n",
            "        [0.0213, 0.9787]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0120, 0.9880],\n",
            "        [0.7321, 0.2679]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0557, 0.9443],\n",
            "        [0.0178, 0.9822]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0549, 0.9451],\n",
            "        [0.0865, 0.9135]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0050, 0.9950],\n",
            "        [0.1096, 0.8904]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1652, 0.8348],\n",
            "        [0.0799, 0.9201]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0220, 0.9780],\n",
            "        [0.1677, 0.8323]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1093, 0.8907],\n",
            "        [0.2012, 0.7988]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1561, 0.8439],\n",
            "        [0.5441, 0.4559]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0275, 0.9725]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3181, 0.6819],\n",
            "        [0.0370, 0.9630]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1280, 0.8720],\n",
            "        [0.7358, 0.2642]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0776, 0.9224],\n",
            "        [0.0254, 0.9746]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4938, 0.5062],\n",
            "        [0.0180, 0.9820]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1361, 0.8639],\n",
            "        [0.0321, 0.9679]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2393, 0.7607],\n",
            "        [0.1104, 0.8896]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1703, 0.8297],\n",
            "        [0.0961, 0.9039]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0162, 0.9838],\n",
            "        [0.0528, 0.9472]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7758, 0.2242],\n",
            "        [0.0547, 0.9453]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5509, 0.4491],\n",
            "        [0.0479, 0.9521]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0421, 0.9579],\n",
            "        [0.0791, 0.9209]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3432, 0.6568],\n",
            "        [0.1715, 0.8285]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0093, 0.9907],\n",
            "        [0.0276, 0.9724]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0168, 0.9832],\n",
            "        [0.4738, 0.5262]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0814, 0.9186],\n",
            "        [0.6162, 0.3838]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0566, 0.9434],\n",
            "        [0.1507, 0.8493]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1598, 0.8402],\n",
            "        [0.0118, 0.9882]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0213, 0.9787],\n",
            "        [0.0227, 0.9773]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5106, 0.4894],\n",
            "        [0.1683, 0.8317]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2540, 0.7460],\n",
            "        [0.0882, 0.9118]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3059, 0.6941],\n",
            "        [0.0523, 0.9477]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1400, 0.8600],\n",
            "        [0.2130, 0.7870]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0548, 0.9452],\n",
            "        [0.0770, 0.9230]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0469, 0.9531],\n",
            "        [0.0692, 0.9308]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0236, 0.9764],\n",
            "        [0.1962, 0.8038]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0231, 0.9769],\n",
            "        [0.1095, 0.8905]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0545, 0.9455],\n",
            "        [0.1968, 0.8032]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2256, 0.7744],\n",
            "        [0.2724, 0.7276]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0529, 0.9471],\n",
            "        [0.0858, 0.9142]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1108, 0.8892],\n",
            "        [0.5140, 0.4860]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0734, 0.9266],\n",
            "        [0.2693, 0.7307]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1126, 0.8874],\n",
            "        [0.0216, 0.9784]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0491, 0.9509],\n",
            "        [0.1257, 0.8743]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0148, 0.9852],\n",
            "        [0.2660, 0.7340]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1481, 0.8519],\n",
            "        [0.0738, 0.9262]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0733, 0.9267],\n",
            "        [0.0726, 0.9274]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0571, 0.9429],\n",
            "        [0.0828, 0.9172]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0219, 0.9781],\n",
            "        [0.2366, 0.7634]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3996, 0.6004],\n",
            "        [0.2033, 0.7967]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0994, 0.9006],\n",
            "        [0.0151, 0.9849]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1367, 0.8633],\n",
            "        [0.0050, 0.9950]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0463, 0.9537]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2350, 0.7650],\n",
            "        [0.0147, 0.9853]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0180, 0.9820],\n",
            "        [0.5644, 0.4356]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1367, 0.8633],\n",
            "        [0.4796, 0.5204]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2663, 0.7337],\n",
            "        [0.2287, 0.7713]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0150, 0.9850],\n",
            "        [0.1749, 0.8251]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1423, 0.8577],\n",
            "        [0.0782, 0.9218]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0551, 0.9449],\n",
            "        [0.0481, 0.9519]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0816, 0.9184],\n",
            "        [0.5025, 0.4975]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1351, 0.8649],\n",
            "        [0.0377, 0.9623]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3056, 0.6944],\n",
            "        [0.1933, 0.8067]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0540, 0.9460],\n",
            "        [0.0953, 0.9047]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5135, 0.4865],\n",
            "        [0.1219, 0.8781]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3882, 0.6118],\n",
            "        [0.2549, 0.7451]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2707, 0.7293],\n",
            "        [0.1271, 0.8729]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0113, 0.9887],\n",
            "        [0.0704, 0.9296]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1482, 0.8518],\n",
            "        [0.0665, 0.9335]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0509, 0.9491],\n",
            "        [0.0213, 0.9787]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3170, 0.6830],\n",
            "        [0.1081, 0.8919]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0219, 0.9781],\n",
            "        [0.0454, 0.9546]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2571, 0.7429],\n",
            "        [0.0701, 0.9299]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0693, 0.9307],\n",
            "        [0.1405, 0.8595]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6182, 0.3818],\n",
            "        [0.0518, 0.9482]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0486, 0.9514],\n",
            "        [0.2116, 0.7884]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0276, 0.9724],\n",
            "        [0.1969, 0.8031]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1995, 0.8005],\n",
            "        [0.0969, 0.9031]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1701, 0.8299],\n",
            "        [0.0698, 0.9302]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0797, 0.9203],\n",
            "        [0.0237, 0.9763]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7821, 0.2179],\n",
            "        [0.2403, 0.7597]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0576, 0.9424],\n",
            "        [0.0157, 0.9843]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0760, 0.9240],\n",
            "        [0.0826, 0.9174]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1096, 0.8904],\n",
            "        [0.0205, 0.9795]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0548, 0.9452],\n",
            "        [0.0417, 0.9583]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0161, 0.9839],\n",
            "        [0.1605, 0.8395]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0247, 0.9753],\n",
            "        [0.0207, 0.9793]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0092, 0.9908],\n",
            "        [0.0048, 0.9952]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0224, 0.9776],\n",
            "        [0.0558, 0.9442]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5077, 0.4923],\n",
            "        [0.0310, 0.9690]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3506, 0.6494],\n",
            "        [0.0770, 0.9230]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7490, 0.2510],\n",
            "        [0.1085, 0.8915]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1118, 0.8882],\n",
            "        [0.0452, 0.9548]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1664, 0.8336],\n",
            "        [0.0892, 0.9108]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0534, 0.9466]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4757, 0.5243],\n",
            "        [0.0277, 0.9723]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2126, 0.7874],\n",
            "        [0.1660, 0.8340]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0542, 0.9458],\n",
            "        [0.0529, 0.9471]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1413, 0.8587],\n",
            "        [0.0488, 0.9512]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1946, 0.8054],\n",
            "        [0.0752, 0.9248]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0542, 0.9458],\n",
            "        [0.1484, 0.8516]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0566, 0.9434],\n",
            "        [0.0664, 0.9336]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0406, 0.9594],\n",
            "        [0.0695, 0.9305]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0300, 0.9700],\n",
            "        [0.0203, 0.9797]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2536, 0.7464],\n",
            "        [0.4961, 0.5039]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0433, 0.9567],\n",
            "        [0.0156, 0.9844]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0939, 0.9061],\n",
            "        [0.0522, 0.9478]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0687, 0.9313],\n",
            "        [0.1356, 0.8644]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2270, 0.7730],\n",
            "        [0.0170, 0.9830]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1026, 0.8974],\n",
            "        [0.1536, 0.8464]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4946, 0.5054],\n",
            "        [0.0498, 0.9502]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0493, 0.9507],\n",
            "        [0.3775, 0.6225]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0045, 0.9955],\n",
            "        [0.3357, 0.6643]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1652, 0.8348],\n",
            "        [0.2462, 0.7538]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0663, 0.9337],\n",
            "        [0.1029, 0.8971]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1168, 0.8832],\n",
            "        [0.1645, 0.8355]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1031, 0.8969],\n",
            "        [0.0767, 0.9233]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0436, 0.9564],\n",
            "        [0.1234, 0.8766]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2505, 0.7495],\n",
            "        [0.0425, 0.9575]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0352, 0.9648],\n",
            "        [0.0200, 0.9800]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0143, 0.9857],\n",
            "        [0.3114, 0.6886]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1271, 0.8729],\n",
            "        [0.1305, 0.8695]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1037, 0.8963],\n",
            "        [0.0208, 0.9792]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5490, 0.4510],\n",
            "        [0.0200, 0.9800]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1896, 0.8104],\n",
            "        [0.0213, 0.9787]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0890, 0.9110],\n",
            "        [0.7750, 0.2250]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2944, 0.7056],\n",
            "        [0.0727, 0.9273]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0514, 0.9486],\n",
            "        [0.0753, 0.9247]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0832, 0.9168],\n",
            "        [0.0769, 0.9231]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7393, 0.2607],\n",
            "        [0.0083, 0.9917]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0138, 0.9862],\n",
            "        [0.2318, 0.7682]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0649, 0.9351],\n",
            "        [0.5091, 0.4909]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0731, 0.9269],\n",
            "        [0.0227, 0.9773]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1884, 0.8116],\n",
            "        [0.6169, 0.3831]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0105, 0.9895],\n",
            "        [0.0192, 0.9808]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2225, 0.7775],\n",
            "        [0.2639, 0.7361]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0134, 0.9866]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1369, 0.8631],\n",
            "        [0.0506, 0.9494]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0684, 0.9316],\n",
            "        [0.1294, 0.8706]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7830, 0.2170],\n",
            "        [0.0672, 0.9328]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1908, 0.8092],\n",
            "        [0.2551, 0.7449]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0742, 0.9258],\n",
            "        [0.1926, 0.8074]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5062, 0.4938],\n",
            "        [0.0208, 0.9792]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5202, 0.4798],\n",
            "        [0.0214, 0.9786]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0367, 0.9633],\n",
            "        [0.0139, 0.9861]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1202, 0.8798],\n",
            "        [0.0780, 0.9220]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1372, 0.8628],\n",
            "        [0.1376, 0.8624]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0045, 0.9955],\n",
            "        [0.0293, 0.9707]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0449, 0.9551],\n",
            "        [0.0433, 0.9567]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0147, 0.9853],\n",
            "        [0.0693, 0.9307]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1946, 0.8054],\n",
            "        [0.0531, 0.9469]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0566, 0.9434],\n",
            "        [0.0105, 0.9895]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0199, 0.9801],\n",
            "        [0.2311, 0.7689]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0786, 0.9214],\n",
            "        [0.0966, 0.9034]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0087, 0.9913],\n",
            "        [0.0794, 0.9206]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0433, 0.9567],\n",
            "        [0.0265, 0.9735]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0739, 0.9261],\n",
            "        [0.6315, 0.3685]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0675, 0.9325],\n",
            "        [0.0233, 0.9767]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0500, 0.9500],\n",
            "        [0.4773, 0.5227]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1747, 0.8253],\n",
            "        [0.1497, 0.8503]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1071, 0.8929],\n",
            "        [0.0193, 0.9807]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5731, 0.4269],\n",
            "        [0.2642, 0.7358]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3022, 0.6978],\n",
            "        [0.1646, 0.8354]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0533, 0.9467],\n",
            "        [0.2641, 0.7359]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0203, 0.9797],\n",
            "        [0.0522, 0.9478]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0406, 0.9594],\n",
            "        [0.2451, 0.7549]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0549, 0.9451],\n",
            "        [0.0490, 0.9510]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0895, 0.9105],\n",
            "        [0.0179, 0.9821]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0978, 0.9022],\n",
            "        [0.0234, 0.9766]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0556, 0.9444],\n",
            "        [0.0150, 0.9850]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1125, 0.8875],\n",
            "        [0.1742, 0.8258]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1067, 0.8933],\n",
            "        [0.1691, 0.8309]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3264, 0.6736],\n",
            "        [0.0693, 0.9307]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3665, 0.6335],\n",
            "        [0.2764, 0.7236]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2456, 0.7544],\n",
            "        [0.7677, 0.2323]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3975, 0.6025],\n",
            "        [0.1315, 0.8685]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0144, 0.9856],\n",
            "        [0.1111, 0.8889]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5294, 0.4706],\n",
            "        [0.0777, 0.9223]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2166, 0.7834]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1102, 0.8898],\n",
            "        [0.1106, 0.8894]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0532, 0.9468],\n",
            "        [0.7662, 0.2338]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0235, 0.9765],\n",
            "        [0.0220, 0.9780]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3628, 0.6372],\n",
            "        [0.0240, 0.9760]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0552, 0.9448],\n",
            "        [0.1677, 0.8323]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2421, 0.7579],\n",
            "        [0.5220, 0.4780]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0441, 0.9559],\n",
            "        [0.1327, 0.8673]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1771, 0.8229],\n",
            "        [0.0104, 0.9896]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0138, 0.9862],\n",
            "        [0.0204, 0.9796]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0689, 0.9311],\n",
            "        [0.0193, 0.9807]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0663, 0.9337],\n",
            "        [0.1638, 0.8362]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0940, 0.9060],\n",
            "        [0.0731, 0.9269]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0957, 0.9043],\n",
            "        [0.1484, 0.8516]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0736, 0.9264],\n",
            "        [0.2379, 0.7621]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1269, 0.8731],\n",
            "        [0.2988, 0.7012]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0133, 0.9867],\n",
            "        [0.0043, 0.9957]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1175, 0.8825],\n",
            "        [0.2706, 0.7294]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1926, 0.8074],\n",
            "        [0.0637, 0.9363]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0146, 0.9854],\n",
            "        [0.0763, 0.9237]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1375, 0.8625],\n",
            "        [0.0761, 0.9239]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1315, 0.8685],\n",
            "        [0.0393, 0.9607]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4648, 0.5352],\n",
            "        [0.2501, 0.7499]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0511, 0.9489],\n",
            "        [0.0196, 0.9804]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7805, 0.2195],\n",
            "        [0.0532, 0.9468]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0352, 0.9648],\n",
            "        [0.1874, 0.8126]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1611, 0.8389],\n",
            "        [0.0721, 0.9279]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4899, 0.5101],\n",
            "        [0.0804, 0.9196]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0406, 0.9594],\n",
            "        [0.0136, 0.9864]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0408, 0.9592],\n",
            "        [0.5112, 0.4888]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0658, 0.9342],\n",
            "        [0.0079, 0.9921]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0494, 0.9506],\n",
            "        [0.0240, 0.9760]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3147, 0.6853],\n",
            "        [0.5568, 0.4432]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2469, 0.7531],\n",
            "        [0.2228, 0.7772]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1860, 0.8140],\n",
            "        [0.0751, 0.9249]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2471, 0.7529],\n",
            "        [0.0164, 0.9836]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1010, 0.8990],\n",
            "        [0.0189, 0.9811]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0513, 0.9487],\n",
            "        [0.0481, 0.9519]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3791, 0.6209],\n",
            "        [0.6263, 0.3737]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1060, 0.8940],\n",
            "        [0.2108, 0.7892]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0655, 0.9345],\n",
            "        [0.0506, 0.9494]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1371, 0.8629],\n",
            "        [0.0283, 0.9717]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0477, 0.9523]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1910, 0.8090],\n",
            "        [0.0712, 0.9288]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2986, 0.7014],\n",
            "        [0.0924, 0.9076]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0422, 0.9578],\n",
            "        [0.0223, 0.9777]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0735, 0.9265],\n",
            "        [0.0531, 0.9469]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0426, 0.9574],\n",
            "        [0.0672, 0.9328]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0648, 0.9352],\n",
            "        [0.0779, 0.9221]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0228, 0.9772],\n",
            "        [0.0207, 0.9793]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1480, 0.8520],\n",
            "        [0.1189, 0.8811]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3250, 0.6750],\n",
            "        [0.1087, 0.8913]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5813, 0.4187],\n",
            "        [0.1617, 0.8383]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0509, 0.9491],\n",
            "        [0.2675, 0.7325]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1946, 0.8054],\n",
            "        [0.1770, 0.8230]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1431, 0.8569],\n",
            "        [0.0881, 0.9119]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1104, 0.8896],\n",
            "        [0.7680, 0.2320]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1398, 0.8602],\n",
            "        [0.0976, 0.9024]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0136, 0.9864],\n",
            "        [0.1309, 0.8691]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0044, 0.9956],\n",
            "        [0.0198, 0.9802]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0146, 0.9854],\n",
            "        [0.5486, 0.4514]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0727, 0.9273],\n",
            "        [0.0421, 0.9579]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1528, 0.8472],\n",
            "        [0.5327, 0.4673]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1747, 0.8253],\n",
            "        [0.0141, 0.9859]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4900, 0.5100],\n",
            "        [0.0558, 0.9442]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2643, 0.7357],\n",
            "        [0.0191, 0.9809]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0453, 0.9547],\n",
            "        [0.0506, 0.9494]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0805, 0.9195],\n",
            "        [0.0553, 0.9447]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0180, 0.9820],\n",
            "        [0.6466, 0.3534]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.8020, 0.1980],\n",
            "        [0.0501, 0.9499]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0291, 0.9709],\n",
            "        [0.0217, 0.9783]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0685, 0.9315],\n",
            "        [0.1332, 0.8668]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2462, 0.7538],\n",
            "        [0.0390, 0.9610]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0550, 0.9450],\n",
            "        [0.1651, 0.8349]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2474, 0.7526],\n",
            "        [0.2162, 0.7838]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0144, 0.9856],\n",
            "        [0.2787, 0.7213]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2417, 0.7583],\n",
            "        [0.0672, 0.9328]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0789, 0.9211],\n",
            "        [0.1092, 0.8908]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2005, 0.7995],\n",
            "        [0.5225, 0.4775]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2725, 0.7275],\n",
            "        [0.0087, 0.9913]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0764, 0.9236],\n",
            "        [0.0202, 0.9798]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3928, 0.6072],\n",
            "        [0.0273, 0.9727]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3652, 0.6348],\n",
            "        [0.1053, 0.8947]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0539, 0.9461],\n",
            "        [0.0100, 0.9900]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0589, 0.9411]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0670, 0.9330],\n",
            "        [0.0086, 0.9914]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0231, 0.9769],\n",
            "        [0.0545, 0.9455]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5218, 0.4782],\n",
            "        [0.5266, 0.4734]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1633, 0.8367],\n",
            "        [0.0736, 0.9264]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0141, 0.9859],\n",
            "        [0.0211, 0.9789]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0042, 0.9958],\n",
            "        [0.3007, 0.6993]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0408, 0.9592],\n",
            "        [0.6440, 0.3560]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0877, 0.9123],\n",
            "        [0.1778, 0.8222]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1918, 0.8082],\n",
            "        [0.1713, 0.8287]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0665, 0.9335],\n",
            "        [0.0783, 0.9217]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3279, 0.6721],\n",
            "        [0.0198, 0.9803]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0185, 0.9815],\n",
            "        [0.0700, 0.9300]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2419, 0.7581],\n",
            "        [0.1944, 0.8056]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0715, 0.9285],\n",
            "        [0.1976, 0.8024]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0141, 0.9859],\n",
            "        [0.0224, 0.9776]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1295, 0.8705],\n",
            "        [0.3862, 0.6138]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0508, 0.9492],\n",
            "        [0.0565, 0.9435]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0097, 0.9903],\n",
            "        [0.7987, 0.2013]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0535, 0.9465],\n",
            "        [0.2547, 0.7453]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2397, 0.7603],\n",
            "        [0.7672, 0.2328]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0170, 0.9830],\n",
            "        [0.2628, 0.7372]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5853, 0.4147],\n",
            "        [0.3543, 0.6457]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0528, 0.9472],\n",
            "        [0.1486, 0.8514]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2359, 0.7641],\n",
            "        [0.5429, 0.4571]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0930, 0.9070],\n",
            "        [0.0515, 0.9485]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1425, 0.8575],\n",
            "        [0.1078, 0.8922]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0527, 0.9473],\n",
            "        [0.0375, 0.9625]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2766, 0.7234],\n",
            "        [0.1282, 0.8718]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1640, 0.8360],\n",
            "        [0.0765, 0.9235]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1350, 0.8650],\n",
            "        [0.1104, 0.8896]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2156, 0.7844],\n",
            "        [0.0779, 0.9221]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0637, 0.9363],\n",
            "        [0.0134, 0.9866]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0190, 0.9810],\n",
            "        [0.1198, 0.8802]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0492, 0.9508],\n",
            "        [0.4832, 0.5168]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0967, 0.9033],\n",
            "        [0.2743, 0.7257]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0414, 0.9586],\n",
            "        [0.0265, 0.9735]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0424, 0.9576],\n",
            "        [0.0281, 0.9719]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0758, 0.9242],\n",
            "        [0.1497, 0.8503]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1033, 0.8967],\n",
            "        [0.0495, 0.9505]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0666, 0.9334],\n",
            "        [0.1073, 0.8927]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0429, 0.9571],\n",
            "        [0.0202, 0.9798]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0130, 0.9870]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2437, 0.7563],\n",
            "        [0.1490, 0.8510]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7727, 0.2273],\n",
            "        [0.2425, 0.7575]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0575, 0.9425],\n",
            "        [0.0201, 0.9799]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0776, 0.9224],\n",
            "        [0.0173, 0.9827]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1941, 0.8059],\n",
            "        [0.5202, 0.4798]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0083, 0.9917],\n",
            "        [0.2994, 0.7006]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0188, 0.9812],\n",
            "        [0.2571, 0.7429]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0380, 0.9620],\n",
            "        [0.0776, 0.9224]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0411, 0.9589],\n",
            "        [0.5293, 0.4707]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1184, 0.8816],\n",
            "        [0.1027, 0.8973]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0426, 0.9574],\n",
            "        [0.2799, 0.7201]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3289, 0.6711],\n",
            "        [0.0947, 0.9053]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0485, 0.9515],\n",
            "        [0.0705, 0.9295]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0699, 0.9301],\n",
            "        [0.1095, 0.8905]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1999, 0.8001],\n",
            "        [0.4811, 0.5189]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0525, 0.9475],\n",
            "        [0.3593, 0.6407]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0536, 0.9464],\n",
            "        [0.0654, 0.9346]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1615, 0.8385],\n",
            "        [0.6451, 0.3549]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1271, 0.8729],\n",
            "        [0.0751, 0.9249]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0610, 0.9390],\n",
            "        [0.0721, 0.9279]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0642, 0.9358],\n",
            "        [0.0860, 0.9140]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1432, 0.8568],\n",
            "        [0.0945, 0.9055]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0193, 0.9807],\n",
            "        [0.0128, 0.9872]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2143, 0.7857],\n",
            "        [0.0485, 0.9515]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0533, 0.9467],\n",
            "        [0.2615, 0.7385]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5459, 0.4541],\n",
            "        [0.0135, 0.9865]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0274, 0.9726],\n",
            "        [0.0039, 0.9961]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0412, 0.9588],\n",
            "        [0.1753, 0.8247]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0402, 0.9598],\n",
            "        [0.1060, 0.8940]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0094, 0.9906],\n",
            "        [0.1280, 0.8720]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1092, 0.8908],\n",
            "        [0.5929, 0.4071]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1612, 0.8388],\n",
            "        [0.2709, 0.7291]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0130, 0.9870],\n",
            "        [0.0177, 0.9823]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1321, 0.8679],\n",
            "        [0.0522, 0.9478]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0647, 0.9353],\n",
            "        [0.3844, 0.6156]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0754, 0.9246],\n",
            "        [0.0217, 0.9783]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0135, 0.9865],\n",
            "        [0.0226, 0.9774]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1905, 0.8095],\n",
            "        [0.2404, 0.7596]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0535, 0.9465],\n",
            "        [0.0261, 0.9739]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1682, 0.8318],\n",
            "        [0.8032, 0.1968]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0498, 0.9502],\n",
            "        [0.0202, 0.9798]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1471, 0.8529]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2394, 0.7606],\n",
            "        [0.4775, 0.5225]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3804, 0.6196],\n",
            "        [0.2733, 0.7267]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2532, 0.7468],\n",
            "        [0.0133, 0.9867]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0133, 0.9867],\n",
            "        [0.5237, 0.4763]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0516, 0.9484],\n",
            "        [0.8009, 0.1991]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0198, 0.9802],\n",
            "        [0.5511, 0.4489]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0588, 0.9412],\n",
            "        [0.0484, 0.9516]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0631, 0.9369],\n",
            "        [0.0168, 0.9832]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0391, 0.9609],\n",
            "        [0.0910, 0.9090]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0079, 0.9921],\n",
            "        [0.1433, 0.8567]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1051, 0.8949],\n",
            "        [0.1262, 0.8738]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0400, 0.9600],\n",
            "        [0.3235, 0.6765]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0632, 0.9368],\n",
            "        [0.0668, 0.9332]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0692, 0.9308],\n",
            "        [0.2573, 0.7427]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0747, 0.9253],\n",
            "        [0.1235, 0.8765]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3496, 0.6504],\n",
            "        [0.1849, 0.8151]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1910, 0.8090],\n",
            "        [0.0558, 0.9442]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0739, 0.9261],\n",
            "        [0.0513, 0.9487]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0124, 0.9876],\n",
            "        [0.2773, 0.7227]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1436, 0.8564],\n",
            "        [0.1265, 0.8735]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1127, 0.8873],\n",
            "        [0.5903, 0.4097]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1948, 0.8052],\n",
            "        [0.5047, 0.4953]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0661, 0.9339],\n",
            "        [0.0524, 0.9476]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0524, 0.9476],\n",
            "        [0.2411, 0.7589]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0189, 0.9811],\n",
            "        [0.7690, 0.2310]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0171, 0.9829],\n",
            "        [0.0397, 0.9603]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0089, 0.9911],\n",
            "        [0.1034, 0.8966]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6459, 0.3541],\n",
            "        [0.0942, 0.9058]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0531, 0.9469],\n",
            "        [0.0376, 0.9624]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2907, 0.7093],\n",
            "        [0.0181, 0.9819]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0125, 0.9875],\n",
            "        [0.2170, 0.7830]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0752, 0.9248],\n",
            "        [0.0483, 0.9517]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1464, 0.8536],\n",
            "        [0.2436, 0.7564]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1605, 0.8395],\n",
            "        [0.0209, 0.9791]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0038, 0.9962],\n",
            "        [0.0868, 0.9132]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0258, 0.9742],\n",
            "        [0.1594, 0.8406]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0495, 0.9505],\n",
            "        [0.1781, 0.8219]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0730, 0.9270],\n",
            "        [0.0191, 0.9809]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0998, 0.9002],\n",
            "        [0.0225, 0.9775]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0400, 0.9600],\n",
            "        [0.1088, 0.8912]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0269, 0.9731],\n",
            "        [0.0631, 0.9369]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1671, 0.8329]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2480, 0.7520],\n",
            "        [0.0950, 0.9050]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1681, 0.8319],\n",
            "        [0.0399, 0.9601]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0089, 0.9911],\n",
            "        [0.1080, 0.8920]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0536, 0.9464],\n",
            "        [0.0638, 0.9362]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1290, 0.8710],\n",
            "        [0.0201, 0.9799]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2179, 0.7821],\n",
            "        [0.2004, 0.7996]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1950, 0.8050],\n",
            "        [0.0596, 0.9404]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0530, 0.9470],\n",
            "        [0.1259, 0.8741]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0936, 0.9064],\n",
            "        [0.2952, 0.7048]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0129, 0.9871],\n",
            "        [0.6553, 0.3447]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0264, 0.9736],\n",
            "        [0.2540, 0.7460]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1875, 0.8125],\n",
            "        [0.0170, 0.9830]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1164, 0.8836],\n",
            "        [0.0744, 0.9256]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5617, 0.4383],\n",
            "        [0.0525, 0.9475]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0694, 0.9306],\n",
            "        [0.0723, 0.9277]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2402, 0.7598],\n",
            "        [0.0757, 0.9243]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1289, 0.8711],\n",
            "        [0.0186, 0.9814]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0527, 0.9473],\n",
            "        [0.1071, 0.8929]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1480, 0.8520],\n",
            "        [0.0749, 0.9251]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0486, 0.9514],\n",
            "        [0.0125, 0.9875]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7802, 0.2198],\n",
            "        [0.0630, 0.9370]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0078, 0.9922],\n",
            "        [0.0975, 0.9025]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0566, 0.9434],\n",
            "        [0.0672, 0.9328]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0037, 0.9963],\n",
            "        [0.1042, 0.8958]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1631, 0.8369],\n",
            "        [0.0201, 0.9799]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0376, 0.9624],\n",
            "        [0.5195, 0.4805]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.8067, 0.1933],\n",
            "        [0.0120, 0.9880]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0252, 0.9748],\n",
            "        [0.0217, 0.9783]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2800, 0.7200],\n",
            "        [0.4808, 0.5192]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0869, 0.9131],\n",
            "        [0.2497, 0.7503]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2709, 0.7291],\n",
            "        [0.0680, 0.9320]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3287, 0.6713],\n",
            "        [0.0407, 0.9593]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1828, 0.8172],\n",
            "        [0.0476, 0.9524]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1556, 0.8444],\n",
            "        [0.0527, 0.9473]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0490, 0.9510],\n",
            "        [0.1615, 0.8385]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0386, 0.9614],\n",
            "        [0.5483, 0.4517]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1495, 0.8505],\n",
            "        [0.0169, 0.9831]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0655, 0.9345],\n",
            "        [0.3827, 0.6173]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0179, 0.9821],\n",
            "        [0.6120, 0.3880]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0192, 0.9808],\n",
            "        [0.2793, 0.7207]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0130, 0.9870],\n",
            "        [0.0408, 0.9592]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3725, 0.6275]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3317, 0.6683],\n",
            "        [0.2969, 0.7031]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0406, 0.9594],\n",
            "        [0.0037, 0.9963]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0126, 0.9874],\n",
            "        [0.8127, 0.1873]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0700, 0.9300],\n",
            "        [0.0680, 0.9320]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1512, 0.8488],\n",
            "        [0.0765, 0.9235]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1102, 0.8898],\n",
            "        [0.0755, 0.9245]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0503, 0.9497],\n",
            "        [0.6628, 0.3372]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1064, 0.8936],\n",
            "        [0.2012, 0.7988]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1309, 0.8691],\n",
            "        [0.0224, 0.9776]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0409, 0.9591],\n",
            "        [0.3697, 0.6303]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3831, 0.6169],\n",
            "        [0.2844, 0.7156]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2196, 0.7804],\n",
            "        [0.0260, 0.9740]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5415, 0.4585],\n",
            "        [0.2746, 0.7254]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0265, 0.9735],\n",
            "        [0.0385, 0.9615]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0964, 0.9036],\n",
            "        [0.0123, 0.9877]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7853, 0.2147],\n",
            "        [0.0080, 0.9920]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0882, 0.9118],\n",
            "        [0.0188, 0.9812]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0632, 0.9368],\n",
            "        [0.2504, 0.7496]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6122, 0.3878],\n",
            "        [0.0179, 0.9821]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1481, 0.8519],\n",
            "        [0.0945, 0.9055]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0640, 0.9360],\n",
            "        [0.0210, 0.9790]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1601, 0.8399],\n",
            "        [0.0527, 0.9473]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5250, 0.4750],\n",
            "        [0.0732, 0.9268]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2492, 0.7508],\n",
            "        [0.0579, 0.9421]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0768, 0.9232],\n",
            "        [0.1720, 0.8280]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0500, 0.9500],\n",
            "        [0.0129, 0.9871]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0546, 0.9454],\n",
            "        [0.0543, 0.9457]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0412, 0.9588],\n",
            "        [0.0087, 0.9913]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1163, 0.8837],\n",
            "        [0.1255, 0.8745]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0532, 0.9468],\n",
            "        [0.2443, 0.7557]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1911, 0.8089],\n",
            "        [0.0190, 0.9810]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0551, 0.9449],\n",
            "        [0.0172, 0.9828]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0483, 0.9517],\n",
            "        [0.5756, 0.4244]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2849, 0.7151],\n",
            "        [0.1001, 0.8999]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0392, 0.9608],\n",
            "        [0.2567, 0.7433]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0201, 0.9799],\n",
            "        [0.1832, 0.8168]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1323, 0.8677],\n",
            "        [0.1109, 0.8891]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0631, 0.9369],\n",
            "        [0.0692, 0.9308]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4833, 0.5167],\n",
            "        [0.0577, 0.9423]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0169, 0.9831],\n",
            "        [0.1966, 0.8034]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1630, 0.8370],\n",
            "        [0.1534, 0.8466]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0126, 0.9874]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1623, 0.8377],\n",
            "        [0.2012, 0.7988]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6620, 0.3380],\n",
            "        [0.0533, 0.9467]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1590, 0.8410],\n",
            "        [0.5371, 0.4629]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0623, 0.9377],\n",
            "        [0.0398, 0.9602]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0167, 0.9833],\n",
            "        [0.0123, 0.9877]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0619, 0.9381],\n",
            "        [0.3316, 0.6684]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0745, 0.9255],\n",
            "        [0.0657, 0.9343]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0743, 0.9257],\n",
            "        [0.0565, 0.9435]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0255, 0.9745],\n",
            "        [0.1786, 0.8214]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1483, 0.8517],\n",
            "        [0.3593, 0.6407]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1290, 0.8710],\n",
            "        [0.0967, 0.9033]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0902, 0.9098],\n",
            "        [0.2486, 0.7514]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0389, 0.9611],\n",
            "        [0.0852, 0.9148]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.8094, 0.1906],\n",
            "        [0.0370, 0.9630]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1122, 0.8878],\n",
            "        [0.0732, 0.9268]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0515, 0.9485],\n",
            "        [0.1045, 0.8955]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0170, 0.9830],\n",
            "        [0.0656, 0.9344]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1653, 0.8347],\n",
            "        [0.0171, 0.9829]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7784, 0.2216],\n",
            "        [0.0116, 0.9884]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0190, 0.9810],\n",
            "        [0.0530, 0.9470]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1043, 0.8957],\n",
            "        [0.0603, 0.9397]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0176, 0.9824],\n",
            "        [0.2151, 0.7849]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2852, 0.7148],\n",
            "        [0.0995, 0.9005]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5099, 0.4901],\n",
            "        [0.2293, 0.7707]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6017, 0.3983],\n",
            "        [0.1432, 0.8568]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2544, 0.7456],\n",
            "        [0.0072, 0.9928]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2715, 0.7285],\n",
            "        [0.0117, 0.9883]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2412, 0.7588],\n",
            "        [0.0034, 0.9966]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1912, 0.8088],\n",
            "        [0.0206, 0.9794]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0499, 0.9501],\n",
            "        [0.0368, 0.9632]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0924, 0.9076],\n",
            "        [0.0119, 0.9881]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0240, 0.9760],\n",
            "        [0.0189, 0.9811]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0509, 0.9491],\n",
            "        [0.0686, 0.9314]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0480, 0.9520],\n",
            "        [0.0492, 0.9508]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0081, 0.9919],\n",
            "        [0.0478, 0.9522]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1460, 0.8540],\n",
            "        [0.1817, 0.8183]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3748, 0.6252],\n",
            "        [0.0377, 0.9623]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0160, 0.9840],\n",
            "        [0.2789, 0.7211]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1204, 0.8796],\n",
            "        [0.2458, 0.7542]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4766, 0.5234],\n",
            "        [0.5693, 0.4307]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0462, 0.9538],\n",
            "        [0.0672, 0.9328]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1239, 0.8761]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1683, 0.8317],\n",
            "        [0.8139, 0.1861]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0666, 0.9334],\n",
            "        [0.0738, 0.9262]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1289, 0.8711],\n",
            "        [0.0195, 0.9805]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0249, 0.9751],\n",
            "        [0.0244, 0.9756]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0522, 0.9478],\n",
            "        [0.3318, 0.6682]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3729, 0.6271],\n",
            "        [0.1061, 0.8939]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1785, 0.8215],\n",
            "        [0.0856, 0.9144]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7872, 0.2128],\n",
            "        [0.0734, 0.9266]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0515, 0.9485],\n",
            "        [0.1455, 0.8545]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0522, 0.9478],\n",
            "        [0.0388, 0.9612]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0603, 0.9397],\n",
            "        [0.0373, 0.9627]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0509, 0.9491],\n",
            "        [0.0931, 0.9069]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2816, 0.7184],\n",
            "        [0.5722, 0.4278]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0462, 0.9538],\n",
            "        [0.0554, 0.9446]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1191, 0.8809],\n",
            "        [0.0159, 0.9841]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0494, 0.9506],\n",
            "        [0.0891, 0.9109]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0477, 0.9523],\n",
            "        [0.0209, 0.9791]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1487, 0.8513],\n",
            "        [0.0483, 0.9517]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1013, 0.8987],\n",
            "        [0.5194, 0.4806]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0603, 0.9397],\n",
            "        [0.6152, 0.3848]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0073, 0.9927],\n",
            "        [0.1061, 0.8939]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0176, 0.9824],\n",
            "        [0.1824, 0.8176]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2802, 0.7198],\n",
            "        [0.0669, 0.9331]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6653, 0.3347],\n",
            "        [0.2874, 0.7126]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2497, 0.7503],\n",
            "        [0.1970, 0.8030]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0118, 0.9882],\n",
            "        [0.0120, 0.9880]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1589, 0.8411],\n",
            "        [0.0641, 0.9359]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2696, 0.7304],\n",
            "        [0.0118, 0.9882]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0692, 0.9308],\n",
            "        [0.2408, 0.7592]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0620, 0.9380],\n",
            "        [0.0548, 0.9452]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0752, 0.9248],\n",
            "        [0.0168, 0.9832]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1670, 0.8330],\n",
            "        [0.1255, 0.8745]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0383, 0.9617],\n",
            "        [0.0391, 0.9609]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0195, 0.9805],\n",
            "        [0.0370, 0.9630]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0985, 0.9015],\n",
            "        [0.2576, 0.7424]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4864, 0.5136],\n",
            "        [0.0116, 0.9884]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0181, 0.9819],\n",
            "        [0.2229, 0.7771]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3743, 0.6257],\n",
            "        [0.0034, 0.9966]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2587, 0.7413],\n",
            "        [0.0080, 0.9920]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1543, 0.8457],\n",
            "        [0.2016, 0.7984]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5517, 0.4483],\n",
            "        [0.1156, 0.8844]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0170, 0.9830]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0527, 0.9473],\n",
            "        [0.0924, 0.9076]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0249, 0.9751],\n",
            "        [0.1237, 0.8763]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0739, 0.9261],\n",
            "        [0.2209, 0.7791]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2896, 0.7104],\n",
            "        [0.1574, 0.8426]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1454, 0.8546],\n",
            "        [0.1292, 0.8708]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0191, 0.9809],\n",
            "        [0.0490, 0.9510]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0599, 0.9401],\n",
            "        [0.0604, 0.9396]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.8166, 0.1834],\n",
            "        [0.0457, 0.9543]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1053, 0.8947],\n",
            "        [0.0116, 0.9884]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5778, 0.4222],\n",
            "        [0.0471, 0.9529]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0033, 0.9967],\n",
            "        [0.2476, 0.7524]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1590, 0.8410],\n",
            "        [0.3677, 0.6323]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1797, 0.8203],\n",
            "        [0.0524, 0.9476]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0368, 0.9632],\n",
            "        [0.1651, 0.8349]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0117, 0.9883],\n",
            "        [0.0373, 0.9627]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3605, 0.6395],\n",
            "        [0.2658, 0.7342]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1980, 0.8020],\n",
            "        [0.0381, 0.9619]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1185, 0.8815],\n",
            "        [0.0559, 0.9441]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0185, 0.9815],\n",
            "        [0.1109, 0.8891]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2337, 0.7663],\n",
            "        [0.0723, 0.9277]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3293, 0.6707],\n",
            "        [0.0168, 0.9832]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5377, 0.4623],\n",
            "        [0.0586, 0.9414]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2830, 0.7170],\n",
            "        [0.0354, 0.9646]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1056, 0.8944],\n",
            "        [0.4689, 0.5311]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1000, 0.9000],\n",
            "        [0.0726, 0.9274]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2424, 0.7576],\n",
            "        [0.0932, 0.9068]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0514, 0.9486],\n",
            "        [0.0648, 0.9352]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0604, 0.9396],\n",
            "        [0.0366, 0.9634]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2733, 0.7267],\n",
            "        [0.7827, 0.2173]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0151, 0.9849],\n",
            "        [0.0508, 0.9492]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0232, 0.9768],\n",
            "        [0.0172, 0.9828]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1894, 0.8106],\n",
            "        [0.0902, 0.9098]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5069, 0.4931],\n",
            "        [0.2484, 0.7516]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0646, 0.9354],\n",
            "        [0.0640, 0.9360]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1461, 0.8539],\n",
            "        [0.0825, 0.9175]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0478, 0.9522],\n",
            "        [0.0158, 0.9842]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0111, 0.9889],\n",
            "        [0.1481, 0.8519]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0501, 0.9499],\n",
            "        [0.6128, 0.3872]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0071, 0.9929],\n",
            "        [0.0112, 0.9888]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0206, 0.9794],\n",
            "        [0.0075, 0.9925]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1742, 0.8258],\n",
            "        [0.0162, 0.9838]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6613, 0.3387]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0369, 0.9631],\n",
            "        [0.0647, 0.9353]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2536, 0.7464],\n",
            "        [0.0726, 0.9274]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0510, 0.9490],\n",
            "        [0.0351, 0.9649]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2322, 0.7678],\n",
            "        [0.0152, 0.9848]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0373, 0.9627],\n",
            "        [0.3592, 0.6408]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4685, 0.5315],\n",
            "        [0.1425, 0.8575]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1174, 0.8826],\n",
            "        [0.0453, 0.9547]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2193, 0.7807],\n",
            "        [0.0072, 0.9928]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1543, 0.8457],\n",
            "        [0.0551, 0.9449]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1049, 0.8951],\n",
            "        [0.6181, 0.3819]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2592, 0.7408],\n",
            "        [0.0074, 0.9926]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0109, 0.9891],\n",
            "        [0.5797, 0.4203]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6643, 0.3357],\n",
            "        [0.0374, 0.9626]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0576, 0.9424],\n",
            "        [0.5361, 0.4639]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0834, 0.9166],\n",
            "        [0.1255, 0.8745]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0162, 0.9838],\n",
            "        [0.0640, 0.9360]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1978, 0.8022],\n",
            "        [0.0113, 0.9887]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0907, 0.9093],\n",
            "        [0.0577, 0.9423]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0713, 0.9287],\n",
            "        [0.0608, 0.9392]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0512, 0.9488],\n",
            "        [0.0031, 0.9969]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5104, 0.4896],\n",
            "        [0.2451, 0.7549]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0702, 0.9298],\n",
            "        [0.3262, 0.6738]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1768, 0.8232],\n",
            "        [0.0177, 0.9823]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0503, 0.9497],\n",
            "        [0.2432, 0.7568]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2808, 0.7192],\n",
            "        [0.7901, 0.2099]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3596, 0.6404],\n",
            "        [0.1003, 0.8997]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0158, 0.9842],\n",
            "        [0.0108, 0.9892]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1014, 0.8986],\n",
            "        [0.1913, 0.8087]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0354, 0.9646],\n",
            "        [0.0177, 0.9823]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0916, 0.9084],\n",
            "        [0.0205, 0.9795]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0479, 0.9521],\n",
            "        [0.0573, 0.9427]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0631, 0.9369],\n",
            "        [0.2795, 0.7205]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0493, 0.9507],\n",
            "        [0.1073, 0.8927]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.8175, 0.1825],\n",
            "        [0.1504, 0.8496]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0875, 0.9125],\n",
            "        [0.1623, 0.8377]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0482, 0.9518],\n",
            "        [0.0464, 0.9536]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1559, 0.8441],\n",
            "        [0.0110, 0.9890]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1762, 0.8238],\n",
            "        [0.0170, 0.9830]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1527, 0.8473],\n",
            "        [0.0236, 0.9764]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0234, 0.9766],\n",
            "        [0.0512, 0.9488]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0161, 0.9839],\n",
            "        [0.2847, 0.7153]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1167, 0.8833]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1174, 0.8826],\n",
            "        [0.1799, 0.8201]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0071, 0.9929],\n",
            "        [0.1058, 0.8942]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2657, 0.7343],\n",
            "        [0.2200, 0.7800]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0357, 0.9643],\n",
            "        [0.0109, 0.9891]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1991, 0.8009],\n",
            "        [0.0470, 0.9530]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0896, 0.9104],\n",
            "        [0.5465, 0.4535]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4719, 0.5281],\n",
            "        [0.3636, 0.6364]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0236, 0.9764],\n",
            "        [0.2428, 0.7572]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0708, 0.9292],\n",
            "        [0.0639, 0.9361]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1083, 0.8917],\n",
            "        [0.1028, 0.8972]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5842, 0.4158],\n",
            "        [0.0502, 0.9498]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2801, 0.7199],\n",
            "        [0.0569, 0.9431]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1509, 0.8491],\n",
            "        [0.0366, 0.9634]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2539, 0.7461],\n",
            "        [0.3286, 0.6714]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0474, 0.9526],\n",
            "        [0.0567, 0.9433]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0111, 0.9889],\n",
            "        [0.0204, 0.9796]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0168, 0.9832],\n",
            "        [0.0107, 0.9893]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2841, 0.7159],\n",
            "        [0.1546, 0.8454]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0486, 0.9514],\n",
            "        [0.2812, 0.7188]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1642, 0.8358],\n",
            "        [0.0707, 0.9293]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0179, 0.9821],\n",
            "        [0.1156, 0.8844]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2330, 0.7670],\n",
            "        [0.0495, 0.9505]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0936, 0.9064],\n",
            "        [0.0110, 0.9890]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1444, 0.8556],\n",
            "        [0.0387, 0.9613]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.8236, 0.1764],\n",
            "        [0.0664, 0.9336]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0348, 0.9652],\n",
            "        [0.0240, 0.9760]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0647, 0.9353],\n",
            "        [0.1018, 0.8982]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0151, 0.9849],\n",
            "        [0.6750, 0.3250]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1796, 0.8204],\n",
            "        [0.3650, 0.6350]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0570, 0.9430],\n",
            "        [0.0185, 0.9815]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0031, 0.9969],\n",
            "        [0.0944, 0.9056]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0074, 0.9926],\n",
            "        [0.1314, 0.8686]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1557, 0.8443],\n",
            "        [0.2555, 0.7445]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6335, 0.3665],\n",
            "        [0.0458, 0.9542]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.7994, 0.2006],\n",
            "        [0.1960, 0.8040]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0524, 0.9476],\n",
            "        [0.0530, 0.9470]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0368, 0.9632],\n",
            "        [0.0162, 0.9838]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5233, 0.4767],\n",
            "        [0.0603, 0.9397]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0165, 0.9835],\n",
            "        [0.0868, 0.9132]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0580, 0.9420],\n",
            "        [0.0538, 0.9462]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0160, 0.9840],\n",
            "        [0.0747, 0.9253]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1570, 0.8430]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0109, 0.9891],\n",
            "        [0.0495, 0.9505]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0744, 0.9256],\n",
            "        [0.1102, 0.8898]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0715, 0.9285],\n",
            "        [0.0647, 0.9353]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0148, 0.9852],\n",
            "        [0.5498, 0.4502]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0585, 0.9415],\n",
            "        [0.0709, 0.9291]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1559, 0.8441],\n",
            "        [0.0482, 0.9518]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0595, 0.9405],\n",
            "        [0.1579, 0.8421]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1278, 0.8722],\n",
            "        [0.1001, 0.8999]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2881, 0.7119],\n",
            "        [0.6741, 0.3259]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5198, 0.4802],\n",
            "        [0.0168, 0.9832]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3627, 0.6373],\n",
            "        [0.0161, 0.9839]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1994, 0.8006],\n",
            "        [0.1542, 0.8458]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0339, 0.9661],\n",
            "        [0.1535, 0.8465]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0924, 0.9076],\n",
            "        [0.0510, 0.9490]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0574, 0.9426],\n",
            "        [0.2650, 0.7350]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0177, 0.9823],\n",
            "        [0.0447, 0.9553]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0348, 0.9652],\n",
            "        [0.0525, 0.9475]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1069, 0.8931],\n",
            "        [0.1772, 0.8228]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2426, 0.7574],\n",
            "        [0.0555, 0.9445]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0363, 0.9637],\n",
            "        [0.1424, 0.8576]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2619, 0.7381],\n",
            "        [0.0234, 0.9766]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0113, 0.9887],\n",
            "        [0.0108, 0.9892]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2888, 0.7112],\n",
            "        [0.1930, 0.8070]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3609, 0.6391],\n",
            "        [0.1794, 0.8206]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2828, 0.7172],\n",
            "        [0.0487, 0.9513]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0566, 0.9434],\n",
            "        [0.0891, 0.9109]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3337, 0.6663],\n",
            "        [0.2216, 0.7784]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1650, 0.8350],\n",
            "        [0.4732, 0.5268]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.6343, 0.3657],\n",
            "        [0.0106, 0.9894]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0377, 0.9623],\n",
            "        [0.1046, 0.8954]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0159, 0.9841],\n",
            "        [0.8029, 0.1971]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0856, 0.9144],\n",
            "        [0.0231, 0.9769]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1154, 0.8846],\n",
            "        [0.2558, 0.7442]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0030, 0.9970],\n",
            "        [0.0177, 0.9823]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0515, 0.9485],\n",
            "        [0.0070, 0.9930]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0630, 0.9370],\n",
            "        [0.0380, 0.9620]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.5966, 0.4034],\n",
            "        [0.0460, 0.9540]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0923, 0.9077],\n",
            "        [0.0156, 0.9844]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0517, 0.9483],\n",
            "        [0.0657, 0.9343]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0070, 0.9930],\n",
            "        [0.1148, 0.8852]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.8260, 0.1740],\n",
            "        [0.2336, 0.7664]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0208, 0.9792]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (12,5))\n",
        "ax = fig.add_subplot(1,2,1)\n",
        "ax.plot(loss_hist, lw = 3)\n",
        "ax.set_title(\"Training loss\",size = 15)\n",
        "ax.set_xlabel(\"Epoch\", size = 15)\n",
        "ax.tick_params(axis = \"both\", which = \"major\", labelsize = 15)\n",
        "ax = fig.add_subplot(1,2,2)\n",
        "ax.plot(accuracy_hist, lw = 3)\n",
        "ax.set_title(\"Training accuracy\", size = 15)\n",
        "ax.set_xlabel(\"Epoch\", size = 15)\n",
        "ax.tick_params(axis = \"both\", which = \"major\", labelsize = 15)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "joRHm_l8NDuc",
        "outputId": "9c6592dc-32a9-44a6-a523-1eb08c987ad3"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#標準化する\n",
        "#X_test_std = (X_test.values - np.mean(X_test.values)) / np.std(X_test.values)\n",
        "\n",
        "#X_test_std = torch.from_numpy(X_test_std).float()\n",
        "#y_test = torch.from_numpy(y_test.values)\n",
        "#pred_test = model(X_test_std)\n",
        "#correct = (torch.argmax(pred_test, dim = 1) == y_test).float()\n",
        "#accuracy = correct.mean()\n",
        "#print(f\"Test Acc : {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "3M4hnoYEQHRV"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#標準化しない\n",
        "\n",
        "X_test_std = torch.from_numpy(X_test.values).float()\n",
        "y_test = torch.from_numpy(y_test.values)\n",
        "pred_test = model(X_test_std)\n",
        "correct = (torch.argmax(pred_test, dim = 1) == y_test).float()\n",
        "accuracy = correct.mean()\n",
        "print(f\"Test Acc : {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-0pWv6DSFOc",
        "outputId": "a1b24c2b-55a6-469d-b6dc-134c7a0b163a"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc : 0.7619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = make_dot(pred_test,params = dict(model.named_parameters()))"
      ],
      "metadata": {
        "id": "dIW5JrwkUftT"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "IC9CpyfpZQAq",
        "outputId": "c21989c7-086f-4866-96d5-d3970ab98516"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"351pt\" height=\"468pt\"\n viewBox=\"0.00 0.00 351.00 468.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 464)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-464 347,-464 347,4 -4,4\"/>\n<!-- 140057127611472 -->\n<g id=\"node1\" class=\"node\">\n<title>140057127611472</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"208,-31 143,-31 143,0 208,0 208,-31\"/>\n<text text-anchor=\"middle\" x=\"175.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (42, 2)</text>\n</g>\n<!-- 140057127566688 -->\n<g id=\"node2\" class=\"node\">\n<title>140057127566688</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"232,-86 119,-86 119,-67 232,-67 232,-86\"/>\n<text text-anchor=\"middle\" x=\"175.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SoftmaxBackward0</text>\n</g>\n<!-- 140057127566688&#45;&gt;140057127611472 -->\n<g id=\"edge14\" class=\"edge\">\n<title>140057127566688&#45;&gt;140057127611472</title>\n<path fill=\"none\" stroke=\"black\" d=\"M175.5,-66.79C175.5,-60.07 175.5,-50.4 175.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"179,-41.19 175.5,-31.19 172,-41.19 179,-41.19\"/>\n</g>\n<!-- 140057127553632 -->\n<g id=\"node3\" class=\"node\">\n<title>140057127553632</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"226,-141 125,-141 125,-122 226,-122 226,-141\"/>\n<text text-anchor=\"middle\" x=\"175.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 140057127553632&#45;&gt;140057127566688 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140057127553632&#45;&gt;140057127566688</title>\n<path fill=\"none\" stroke=\"black\" d=\"M175.5,-121.75C175.5,-114.8 175.5,-104.85 175.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"179,-96.09 175.5,-86.09 172,-96.09 179,-96.09\"/>\n</g>\n<!-- 140057127556896 -->\n<g id=\"node4\" class=\"node\">\n<title>140057127556896</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140057127556896&#45;&gt;140057127553632 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140057127556896&#45;&gt;140057127553632</title>\n<path fill=\"none\" stroke=\"black\" d=\"M70.58,-176.98C90.87,-168.38 122.46,-154.99 145.67,-145.15\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"147.21,-148.3 155.05,-141.17 144.48,-141.85 147.21,-148.3\"/>\n</g>\n<!-- 140057129408272 -->\n<g id=\"node5\" class=\"node\">\n<title>140057129408272</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"92,-262 9,-262 9,-232 92,-232 92,-262\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\">layer2.bias</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n</g>\n<!-- 140057129408272&#45;&gt;140057127556896 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140057129408272&#45;&gt;140057127556896</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.84C50.5,-224.21 50.5,-214.7 50.5,-206.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.27 50.5,-196.27 47,-206.27 54,-206.27\"/>\n</g>\n<!-- 140057127559824 -->\n<g id=\"node6\" class=\"node\">\n<title>140057127559824</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"232,-196 119,-196 119,-177 232,-177 232,-196\"/>\n<text text-anchor=\"middle\" x=\"175.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">SigmoidBackward0</text>\n</g>\n<!-- 140057127559824&#45;&gt;140057127553632 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140057127559824&#45;&gt;140057127553632</title>\n<path fill=\"none\" stroke=\"black\" d=\"M175.5,-176.75C175.5,-169.8 175.5,-159.85 175.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"179,-151.09 175.5,-141.09 172,-151.09 179,-151.09\"/>\n</g>\n<!-- 140057127558816 -->\n<g id=\"node7\" class=\"node\">\n<title>140057127558816</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"224,-256.5 123,-256.5 123,-237.5 224,-237.5 224,-256.5\"/>\n<text text-anchor=\"middle\" x=\"173.5\" y=\"-244.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 140057127558816&#45;&gt;140057127559824 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140057127558816&#45;&gt;140057127559824</title>\n<path fill=\"none\" stroke=\"black\" d=\"M173.8,-237.37C174.07,-229.25 174.5,-216.81 174.85,-206.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"178.36,-206.28 175.2,-196.17 171.36,-206.04 178.36,-206.28\"/>\n</g>\n<!-- 140057127557664 -->\n<g id=\"node8\" class=\"node\">\n<title>140057127557664</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"123,-322.5 22,-322.5 22,-303.5 123,-303.5 123,-322.5\"/>\n<text text-anchor=\"middle\" x=\"72.5\" y=\"-310.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140057127557664&#45;&gt;140057127558816 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140057127557664&#45;&gt;140057127558816</title>\n<path fill=\"none\" stroke=\"black\" d=\"M86.12,-303.37C102.84,-292.78 131.41,-274.67 151.31,-262.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"153.2,-265.01 159.77,-256.7 149.45,-259.1 153.2,-265.01\"/>\n</g>\n<!-- 140057129019216 -->\n<g id=\"node9\" class=\"node\">\n<title>140057129019216</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"113,-394 30,-394 30,-364 113,-364 113,-394\"/>\n<text text-anchor=\"middle\" x=\"71.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\">layer1.bias</text>\n<text text-anchor=\"middle\" x=\"71.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\"> (16)</text>\n</g>\n<!-- 140057129019216&#45;&gt;140057127557664 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140057129019216&#45;&gt;140057127557664</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71.72,-363.8C71.86,-354.7 72.05,-342.79 72.2,-332.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"75.71,-332.9 72.36,-322.84 68.71,-332.79 75.71,-332.9\"/>\n</g>\n<!-- 140057127558768 -->\n<g id=\"node10\" class=\"node\">\n<title>140057127558768</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"219,-322.5 142,-322.5 142,-303.5 219,-303.5 219,-322.5\"/>\n<text text-anchor=\"middle\" x=\"180.5\" y=\"-310.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 140057127558768&#45;&gt;140057127558816 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140057127558768&#45;&gt;140057127558816</title>\n<path fill=\"none\" stroke=\"black\" d=\"M179.56,-303.37C178.54,-294.07 176.89,-278.98 175.57,-266.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"179.04,-266.47 174.47,-256.91 172.08,-267.23 179.04,-266.47\"/>\n</g>\n<!-- 140057127560160 -->\n<g id=\"node11\" class=\"node\">\n<title>140057127560160</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"232,-388.5 131,-388.5 131,-369.5 232,-369.5 232,-388.5\"/>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-376.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140057127560160&#45;&gt;140057127558768 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140057127560160&#45;&gt;140057127558768</title>\n<path fill=\"none\" stroke=\"black\" d=\"M181.37,-369.37C181.22,-360.16 180.99,-345.29 180.8,-333.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"184.3,-332.85 180.64,-322.91 177.3,-332.96 184.3,-332.85\"/>\n</g>\n<!-- 140058960041824 -->\n<g id=\"node12\" class=\"node\">\n<title>140058960041824</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"229,-460 134,-460 134,-430 229,-430 229,-460\"/>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-448\" font-family=\"monospace\" font-size=\"10.00\">layer1.weight</text>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-437\" font-family=\"monospace\" font-size=\"10.00\"> (16, 5000)</text>\n</g>\n<!-- 140058960041824&#45;&gt;140057127560160 -->\n<g id=\"edge10\" class=\"edge\">\n<title>140058960041824&#45;&gt;140057127560160</title>\n<path fill=\"none\" stroke=\"black\" d=\"M181.5,-429.8C181.5,-420.7 181.5,-408.79 181.5,-398.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"185,-398.84 181.5,-388.84 178,-398.84 185,-398.84\"/>\n</g>\n<!-- 140057127562464 -->\n<g id=\"node13\" class=\"node\">\n<title>140057127562464</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"328,-196 251,-196 251,-177 328,-177 328,-196\"/>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 140057127562464&#45;&gt;140057127553632 -->\n<g id=\"edge11\" class=\"edge\">\n<title>140057127562464&#45;&gt;140057127553632</title>\n<path fill=\"none\" stroke=\"black\" d=\"M271.18,-176.98C252.84,-168.46 224.39,-155.23 203.27,-145.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"204.69,-142.21 194.15,-141.17 201.74,-148.56 204.69,-142.21\"/>\n</g>\n<!-- 140057127567024 -->\n<g id=\"node14\" class=\"node\">\n<title>140057127567024</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"343,-256.5 242,-256.5 242,-237.5 343,-237.5 343,-256.5\"/>\n<text text-anchor=\"middle\" x=\"292.5\" y=\"-244.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140057127567024&#45;&gt;140057127562464 -->\n<g id=\"edge12\" class=\"edge\">\n<title>140057127567024&#45;&gt;140057127562464</title>\n<path fill=\"none\" stroke=\"black\" d=\"M292.06,-237.37C291.64,-229.25 291,-216.81 290.47,-206.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"293.95,-205.97 289.94,-196.17 286.96,-206.33 293.95,-205.97\"/>\n</g>\n<!-- 140057129014656 -->\n<g id=\"node15\" class=\"node\">\n<title>140057129014656</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"340,-328 245,-328 245,-298 340,-298 340,-328\"/>\n<text text-anchor=\"middle\" x=\"292.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\">layer2.weight</text>\n<text text-anchor=\"middle\" x=\"292.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\"> (2, 16)</text>\n</g>\n<!-- 140057129014656&#45;&gt;140057127567024 -->\n<g id=\"edge13\" class=\"edge\">\n<title>140057129014656&#45;&gt;140057127567024</title>\n<path fill=\"none\" stroke=\"black\" d=\"M292.5,-297.8C292.5,-288.7 292.5,-276.79 292.5,-266.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"296,-266.84 292.5,-256.84 289,-266.84 296,-266.84\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7f6197563e20>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxqUcMWyXSDR",
        "outputId": "8ee385be-3e89-4337-c2cb-b28ac0599f69"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (layer1): Linear(in_features=5000, out_features=16, bias=True)\n",
            "  (layer2): Linear(in_features=16, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amCHpsfQYf7T",
        "outputId": "6d77f298-f211-4636-ed27-b398dbc43563"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "Model                                    --\n",
              "├─Linear: 1-1                            80,016\n",
              "├─Linear: 1-2                            34\n",
              "=================================================================\n",
              "Total params: 80,050\n",
              "Trainable params: 80,050\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YeYrAQ1_Y9yM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}